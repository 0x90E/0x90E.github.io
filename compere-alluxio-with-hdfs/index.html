<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />



  <link rel="icon" type="image/png" sizes="32x32" href="/images/custom-favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/custom-favicon-16x16-next.png?v=5.1.3">






  <meta name="keywords" content="Hadoop,Alluxio,HDFS,Spark," />










<meta name="description" content="Compere Alluxio with HDFSPurpose 在Hadoop上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。 在Spark上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。  Prepare for Testing File1234567891011# 測試文件大小大約為18.2MB[hadoop@testmain ~]">
<meta name="keywords" content="Hadoop,Alluxio,HDFS,Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Compere Alluxio with HDFS">
<meta property="og:url" content="https://0x90e.github.io/compere-alluxio-with-hdfs/index.html">
<meta property="og:site_name" content="0x90e&#39;s Blog">
<meta property="og:description" content="Compere Alluxio with HDFSPurpose 在Hadoop上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。 在Spark上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。  Prepare for Testing File1234567891011# 測試文件大小大約為18.2MB[hadoop@testmain ~]">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://0x90e.github.io/2017/11/09/spark_alluxio.png">
<meta property="og:image" content="https://0x90e.github.io/2017/11/09/spark_hdfs.png">
<meta property="og:updated_time" content="2017-12-22T17:00:37.055Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Compere Alluxio with HDFS">
<meta name="twitter:description" content="Compere Alluxio with HDFSPurpose 在Hadoop上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。 在Spark上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。  Prepare for Testing File1234567891011# 測試文件大小大約為18.2MB[hadoop@testmain ~]">
<meta name="twitter:image" content="https://0x90e.github.io/2017/11/09/spark_alluxio.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://0x90e.github.io/compere-alluxio-with-hdfs/"/>





  <title>Compere Alluxio with HDFS | 0x90e's Blog</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-107755816-1', 'auto');
  ga('send', 'pageview');
</script>





</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">0x90e's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">Chase Excellence,<br/>Sucess will follow.</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://0x90e.github.io/compere-alluxio-with-hdfs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="0x90e">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="0x90e's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">Compere Alluxio with HDFS</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-08T01:58:46+08:00">
                2017-11-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-data/" itemprop="url" rel="index">
                    <span itemprop="name">Big data</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>Page View
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="Compere-Alluxio-with-HDFS"><a href="#Compere-Alluxio-with-HDFS" class="headerlink" title="Compere Alluxio with HDFS"></a>Compere Alluxio with HDFS</h3><h3 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h3><ol>
<li>在Hadoop上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。</li>
<li>在Spark上，對Alluxio與HDFS中的文件進行操作，比較其讀入的數據量和執行速度。</li>
</ol>
<h3 id="Prepare-for-Testing-File"><a href="#Prepare-for-Testing-File" class="headerlink" title="Prepare for Testing File"></a>Prepare for Testing File</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 測試文件大小大約為18.2MB</span></div><div class="line">[hadoop@testmain ~]<span class="comment"># ll page_views.dat </span></div><div class="line">-rwxr-xr-x 1 root root 19014993 Nov  5 00:21 page_views.dat</div><div class="line"></div><div class="line"><span class="comment"># 將文件上傳至Alluxio</span></div><div class="line">[hadoop@testmain ~]<span class="comment"># alluxio fs mkdir /wordcount/input/</span></div><div class="line">Successfully created directory /wordcount/input/</div><div class="line">[root@testmain ~]<span class="comment"># alluxio fs copyFromLocal page_views.dat /wordcount/input/</span></div><div class="line"></div><div class="line"><span class="comment"># 將文件上傳至HDFS</span></div><div class="line">[hadoop@testmain ~]$ hdfs dfs -put page_views.dat /wordcount/input/</div></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="Hadoop-Testing"><a href="#Hadoop-Testing" class="headerlink" title="Hadoop Testing"></a>Hadoop Testing</h3><ul>
<li>使用Hadoop自帶的測試包中的wordcount，並分別讀取Alluxio與HDFS中的文件，進行測試。<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 對Alluxio中的文件進行測試</span></div><div class="line">[hadoop@testmain ~]$ hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar wordcount -libjars <span class="variable">$ALLUXIO_HOME</span>/client/hadoop/alluxio-1.6.0-hadoop-client.jar alluxio://localhost:19998/wordcount/input/page_views.dat alluxio://localhost:19998/wordcount/output</div><div class="line"><span class="comment"># ...</span></div><div class="line">17/11/08 01:24:17 INFO mapreduce.Job:  map 0% reduce 0%</div><div class="line">17/11/08 01:24:19 INFO mapred.LocalJobRunner: </div><div class="line">17/11/08 01:24:19 INFO mapred.MapTask: Starting flush of map output</div><div class="line">17/11/08 01:24:19 INFO mapred.MapTask: Spilling map output</div><div class="line">17/11/08 01:24:19 INFO mapred.MapTask: bufstart = 0; bufend = 22090342; bufvoid = 104857600</div><div class="line">17/11/08 01:24:19 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23122784(92491136); length = 3091613/6553600</div><div class="line">17/11/08 01:24:21 INFO mapred.MapTask: Finished spill 0</div><div class="line">17/11/08 01:24:21 INFO mapred.Task: Task:attempt_local1066655942_0001_m_000000_0 is <span class="keyword">done</span>. And is <span class="keyword">in</span> the process of committing</div><div class="line">17/11/08 01:24:21 INFO mapred.LocalJobRunner: map</div><div class="line">17/11/08 01:24:21 INFO mapred.Task: Task <span class="string">'attempt_local1066655942_0001_m_000000_0'</span> <span class="keyword">done</span>.</div><div class="line">17/11/08 01:24:21 INFO mapred.LocalJobRunner: Finishing task: attempt_local1066655942_0001_m_000000_0</div><div class="line">17/11/08 01:24:21 INFO mapred.LocalJobRunner: map task executor complete.</div><div class="line">17/11/08 01:24:21 INFO mapred.LocalJobRunner: Waiting <span class="keyword">for</span> reduce tasks</div><div class="line">17/11/08 01:24:21 INFO mapred.LocalJobRunner: Starting task: attempt_local1066655942_0001_r_000000_0</div><div class="line">17/11/08 01:24:21 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1</div><div class="line">17/11/08 01:24:21 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:<span class="literal">false</span>, ignore cleanup failures: <span class="literal">false</span></div><div class="line">17/11/08 01:24:21 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]</div><div class="line">17/11/08 01:24:21 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7df3efe2</div><div class="line">17/11/08 01:24:21 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10</div><div class="line">17/11/08 01:24:21 INFO reduce.EventFetcher: attempt_local1066655942_0001_r_000000_0 Thread started: EventFetcher <span class="keyword">for</span> fetching Map Completion Events</div><div class="line">17/11/08 01:24:21 INFO mapreduce.Job:  map 100% reduce 0%</div><div class="line">17/11/08 01:24:21 INFO reduce.LocalFetcher: localfetcher<span class="comment">#1 about to shuffle output of map attempt_local1066655942_0001_m_000000_0 decomp: 7915818 len: 7915822 to MEMORY</span></div><div class="line">17/11/08 01:24:21 INFO reduce.InMemoryMapOutput: Read 7915818 bytes from map-output <span class="keyword">for</span> attempt_local1066655942_0001_m_000000_0</div><div class="line">17/11/08 01:24:21 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 7915818, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;7915818</div><div class="line">17/11/08 01:24:21 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning</div><div class="line">17/11/08 01:24:21 INFO mapred.LocalJobRunner: 1 / 1 copied.</div><div class="line">17/11/08 01:24:21 INFO reduce.MergeManagerImpl: finalMerge called with 1 <span class="keyword">in</span>-memory map-outputs and 0 on-disk map-outputs</div><div class="line">17/11/08 01:24:21 INFO mapred.Merger: Merging 1 sorted segments</div><div class="line">17/11/08 01:24:21 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7915768 bytes</div><div class="line">17/11/08 01:24:22 INFO reduce.MergeManagerImpl: Merged 1 segments, 7915818 bytes to disk to satisfy reduce memory <span class="built_in">limit</span></div><div class="line">17/11/08 01:24:22 INFO reduce.MergeManagerImpl: Merging 1 files, 7915822 bytes from disk</div><div class="line">17/11/08 01:24:22 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce</div><div class="line">17/11/08 01:24:22 INFO mapred.Merger: Merging 1 sorted segments</div><div class="line">17/11/08 01:24:22 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7915768 bytes</div><div class="line">17/11/08 01:24:22 INFO mapred.LocalJobRunner: 1 / 1 copied.</div><div class="line">17/11/08 01:24:22 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords</div><div class="line">17/11/08 01:24:23 INFO mapred.Task: Task:attempt_local1066655942_0001_r_000000_0 is <span class="keyword">done</span>. And is <span class="keyword">in</span> the process of committing</div><div class="line">17/11/08 01:24:23 INFO mapred.LocalJobRunner: 1 / 1 copied.</div><div class="line">17/11/08 01:24:23 INFO mapred.Task: Task attempt_local1066655942_0001_r_000000_0 is allowed to commit now</div><div class="line">17/11/08 01:24:23 INFO output.FileOutputCommitter: Saved output of task <span class="string">'attempt_local1066655942_0001_r_000000_0'</span> to alluxio://localhost:19998/wordcount/output/_temporary/0/task_local1066655942_0001_r_000000</div><div class="line">17/11/08 01:24:23 INFO mapred.LocalJobRunner: reduce &gt; reduce</div><div class="line">17/11/08 01:24:23 INFO mapred.Task: Task <span class="string">'attempt_local1066655942_0001_r_000000_0'</span> <span class="keyword">done</span>.</div><div class="line">17/11/08 01:24:23 INFO mapred.LocalJobRunner: Finishing task: attempt_local1066655942_0001_r_000000_0</div><div class="line">17/11/08 01:24:23 INFO mapred.LocalJobRunner: reduce task executor complete.</div><div class="line">17/11/08 01:24:24 INFO mapreduce.Job:  map 100% reduce 100%</div><div class="line">17/11/08 01:24:24 INFO mapreduce.Job: Job job_local1066655942_0001 completed successfully</div><div class="line">17/11/08 01:24:24 INFO mapreduce.Job: Counters: 40</div><div class="line">	File System Counters</div><div class="line">		ALLUXIO: Number of bytes <span class="built_in">read</span>=38029986</div><div class="line">		ALLUXIO: Number of bytes written=7281357</div><div class="line">		ALLUXIO: Number of <span class="built_in">read</span> operations=13</div><div class="line">		ALLUXIO: Number of large <span class="built_in">read</span> operations=0</div><div class="line">		ALLUXIO: Number of write operations=4</div><div class="line">		FILE: Number of bytes <span class="built_in">read</span>=52010784</div><div class="line">		FILE: Number of bytes written=60859072</div><div class="line">		FILE: Number of <span class="built_in">read</span> operations=0</div><div class="line">		FILE: Number of large <span class="built_in">read</span> operations=0</div><div class="line">		FILE: Number of write operations=0</div><div class="line">		HDFS: Number of bytes <span class="built_in">read</span>=0</div><div class="line">		HDFS: Number of bytes written=0</div><div class="line">		HDFS: Number of <span class="built_in">read</span> operations=0</div><div class="line">		HDFS: Number of large <span class="built_in">read</span> operations=0</div><div class="line">		HDFS: Number of write operations=0</div><div class="line">	Map-Reduce Framework</div><div class="line">		Map input records=100000</div><div class="line">		Map output records=772904</div><div class="line">		Map output bytes=22090342</div><div class="line">		Map output materialized bytes=7915822</div><div class="line">		Input split bytes=121</div><div class="line">		Combine input records=772904</div><div class="line">		Combine output records=157240</div><div class="line">		Reduce input groups=157240</div><div class="line">		Reduce shuffle bytes=7915822</div><div class="line">		Reduce input records=157240</div><div class="line">		Reduce output records=157240</div><div class="line">		Spilled Records=314480</div><div class="line">		Shuffled Maps =1</div><div class="line">		Failed Shuffles=0</div><div class="line">		Merged Map outputs=1</div><div class="line">		GC time elapsed (ms)=85</div><div class="line">		Total committed heap usage (bytes)=331489280</div><div class="line">	Shuffle Errors</div><div class="line">		BAD_ID=0</div><div class="line">		CONNECTION=0</div><div class="line">		IO_ERROR=0</div><div class="line">		WRONG_LENGTH=0</div><div class="line">		WRONG_MAP=0</div><div class="line">		WRONG_REDUCE=0</div><div class="line">	File Input Format Counters </div><div class="line">		Bytes Read=19014993</div><div class="line">	File Output Format Counters </div><div class="line">		Bytes Written=7281357</div><div class="line">17/11/08 01:24:24 INFO connection.NettyChannelPool: Channel closed</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 對HDFS中的文件進行測試</span></div><div class="line">[hadoop@testmain ~]$ hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar wordcount hdfs://192.168.128.91:9000/wordcount/input/page_views.dat hdfs://192.168.128.91:9000/wordcount/output</div><div class="line"><span class="comment"># ...</span></div><div class="line">17/11/08 01:25:08 INFO mapreduce.Job:  map 0% reduce 0%</div><div class="line">17/11/08 01:25:09 INFO mapred.LocalJobRunner: </div><div class="line">17/11/08 01:25:09 INFO mapred.MapTask: Starting flush of map output</div><div class="line">17/11/08 01:25:09 INFO mapred.MapTask: Spilling map output</div><div class="line">17/11/08 01:25:09 INFO mapred.MapTask: bufstart = 0; bufend = 22090342; bufvoid = 104857600</div><div class="line">17/11/08 01:25:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23122784(92491136); length = 3091613/6553600</div><div class="line">17/11/08 01:25:11 INFO mapred.MapTask: Finished spill 0</div><div class="line">17/11/08 01:25:11 INFO mapred.Task: Task:attempt_local556577714_0001_m_000000_0 is <span class="keyword">done</span>. And is <span class="keyword">in</span> the process of committing</div><div class="line">17/11/08 01:25:11 INFO mapred.LocalJobRunner: map</div><div class="line">17/11/08 01:25:11 INFO mapred.Task: Task <span class="string">'attempt_local556577714_0001_m_000000_0'</span> <span class="keyword">done</span>.</div><div class="line">17/11/08 01:25:11 INFO mapred.LocalJobRunner: Finishing task: attempt_local556577714_0001_m_000000_0</div><div class="line">17/11/08 01:25:11 INFO mapred.LocalJobRunner: map task executor complete.</div><div class="line">17/11/08 01:25:11 INFO mapred.LocalJobRunner: Waiting <span class="keyword">for</span> reduce tasks</div><div class="line">17/11/08 01:25:11 INFO mapred.LocalJobRunner: Starting task: attempt_local556577714_0001_r_000000_0</div><div class="line">17/11/08 01:25:11 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1</div><div class="line">17/11/08 01:25:11 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:<span class="literal">false</span>, ignore cleanup failures: <span class="literal">false</span></div><div class="line">17/11/08 01:25:11 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]</div><div class="line">17/11/08 01:25:11 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@38c32694</div><div class="line">17/11/08 01:25:11 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10</div><div class="line">17/11/08 01:25:11 INFO reduce.EventFetcher: attempt_local556577714_0001_r_000000_0 Thread started: EventFetcher <span class="keyword">for</span> fetching Map Completion Events</div><div class="line">17/11/08 01:25:11 INFO reduce.LocalFetcher: localfetcher<span class="comment">#1 about to shuffle output of map attempt_local556577714_0001_m_000000_0 decomp: 7915818 len: 7915822 to MEMORY</span></div><div class="line">17/11/08 01:25:11 INFO reduce.InMemoryMapOutput: Read 7915818 bytes from map-output <span class="keyword">for</span> attempt_local556577714_0001_m_000000_0</div><div class="line">17/11/08 01:25:11 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 7915818, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;7915818</div><div class="line">17/11/08 01:25:11 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning</div><div class="line">17/11/08 01:25:11 INFO mapred.LocalJobRunner: 1 / 1 copied.</div><div class="line">17/11/08 01:25:11 INFO reduce.MergeManagerImpl: finalMerge called with 1 <span class="keyword">in</span>-memory map-outputs and 0 on-disk map-outputs</div><div class="line">17/11/08 01:25:11 INFO mapred.Merger: Merging 1 sorted segments</div><div class="line">17/11/08 01:25:11 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7915768 bytes</div><div class="line">17/11/08 01:25:11 INFO reduce.MergeManagerImpl: Merged 1 segments, 7915818 bytes to disk to satisfy reduce memory <span class="built_in">limit</span></div><div class="line">17/11/08 01:25:11 INFO reduce.MergeManagerImpl: Merging 1 files, 7915822 bytes from disk</div><div class="line">17/11/08 01:25:11 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce</div><div class="line">17/11/08 01:25:11 INFO mapred.Merger: Merging 1 sorted segments</div><div class="line">17/11/08 01:25:11 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7915768 bytes</div><div class="line">17/11/08 01:25:11 INFO mapred.LocalJobRunner: 1 / 1 copied.</div><div class="line">17/11/08 01:25:11 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords</div><div class="line">17/11/08 01:25:11 INFO mapreduce.Job:  map 100% reduce 0%</div><div class="line">17/11/08 01:25:12 INFO mapred.Task: Task:attempt_local556577714_0001_r_000000_0 is <span class="keyword">done</span>. And is <span class="keyword">in</span> the process of committing</div><div class="line">17/11/08 01:25:12 INFO mapred.LocalJobRunner: 1 / 1 copied.</div><div class="line">17/11/08 01:25:12 INFO mapred.Task: Task attempt_local556577714_0001_r_000000_0 is allowed to commit now</div><div class="line">17/11/08 01:25:12 INFO output.FileOutputCommitter: Saved output of task <span class="string">'attempt_local556577714_0001_r_000000_0'</span> to hdfs://192.168.128.91:9000/wordcount/output/_temporary/0/task_local556577714_0001_r_000000</div><div class="line">17/11/08 01:25:12 INFO mapred.LocalJobRunner: reduce &gt; reduce</div><div class="line">17/11/08 01:25:12 INFO mapred.Task: Task <span class="string">'attempt_local556577714_0001_r_000000_0'</span> <span class="keyword">done</span>.</div><div class="line">17/11/08 01:25:12 INFO mapred.LocalJobRunner: Finishing task: attempt_local556577714_0001_r_000000_0</div><div class="line">17/11/08 01:25:12 INFO mapred.LocalJobRunner: reduce task executor complete.</div><div class="line">17/11/08 01:25:12 INFO mapreduce.Job:  map 100% reduce 100%</div><div class="line">17/11/08 01:25:12 INFO mapreduce.Job: Job job_local556577714_0001 completed successfully</div><div class="line">17/11/08 01:25:12 INFO mapreduce.Job: Counters: 35</div><div class="line">	File System Counters</div><div class="line">		FILE: Number of bytes <span class="built_in">read</span>=16435224</div><div class="line">		FILE: Number of bytes written=24996682</div><div class="line">		FILE: Number of <span class="built_in">read</span> operations=0</div><div class="line">		FILE: Number of large <span class="built_in">read</span> operations=0</div><div class="line">		FILE: Number of write operations=0</div><div class="line">		HDFS: Number of bytes <span class="built_in">read</span>=38029986</div><div class="line">		HDFS: Number of bytes written=7281357</div><div class="line">		HDFS: Number of <span class="built_in">read</span> operations=13</div><div class="line">		HDFS: Number of large <span class="built_in">read</span> operations=0</div><div class="line">		HDFS: Number of write operations=4</div><div class="line">	Map-Reduce Framework</div><div class="line">		Map input records=100000</div><div class="line">		Map output records=772904</div><div class="line">		Map output bytes=22090342</div><div class="line">		Map output materialized bytes=7915822</div><div class="line">		Input split bytes=122</div><div class="line">		Combine input records=772904</div><div class="line">		Combine output records=157240</div><div class="line">		Reduce input groups=157240</div><div class="line">		Reduce shuffle bytes=7915822</div><div class="line">		Reduce input records=157240</div><div class="line">		Reduce output records=157240</div><div class="line">		Spilled Records=314480</div><div class="line">		Shuffled Maps =1</div><div class="line">		Failed Shuffles=0</div><div class="line">		Merged Map outputs=1</div><div class="line">		GC time elapsed (ms)=69</div><div class="line">		Total committed heap usage (bytes)=331489280</div><div class="line">	Shuffle Errors</div><div class="line">		BAD_ID=0</div><div class="line">		CONNECTION=0</div><div class="line">		IO_ERROR=0</div><div class="line">		WRONG_LENGTH=0</div><div class="line">		WRONG_MAP=0</div><div class="line">		WRONG_REDUCE=0</div><div class="line">	File Input Format Counters </div><div class="line">		Bytes Read=19014993</div><div class="line">	File Output Format Counters </div><div class="line">		Bytes Written=7281357</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Spark-Testing"><a href="#Spark-Testing" class="headerlink" title="Spark Testing"></a>Spark Testing</h3><ul>
<li><p>使用Spark shell執行wordcount，並分別讀取Alluxio與HDFS中的文件，進行測試。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 刪除Alluxio與Hdfs的輸出文件，避免在此步驟出現錯誤</span></div><div class="line">[hadoop@testmain ~]$ alluxio fs rm -R /wordcount/output</div><div class="line">/wordcount/output has been removed</div><div class="line">[hadoop@testmain ~]$ hdfs dfs -rm -r /wordcount/output</div><div class="line">Deleted /wordcount/output</div><div class="line"></div><div class="line"><span class="comment"># 執行Spark shell</span></div><div class="line">[hadoop@testmain ~]$ spark-shell --master <span class="built_in">local</span>[2]</div><div class="line">Spark context Web UI available at http://192.168.128.91:4040</div><div class="line"><span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="comment"># 對Alluxio中的文件進行測試</span></div><div class="line">scala&gt; val textFile = sc.textFile(<span class="string">"alluxio://192.168.128.91:19998/wordcount/input/page_views.dat"</span>)</div><div class="line">textFile: org.apache.spark.rdd.RDD[String] = alluxio://192.168.128.91:19998/wordcount/input/page_views.dat MapPartitionsRDD[1] at textFile at &lt;console&gt;:24</div><div class="line"></div><div class="line">scala&gt; val counts = textFile.flatMap(line =&gt; line.split(<span class="string">"\t"</span>)).map(word =&gt; (word, 1)).reduceByKey(_ + _)</div><div class="line">counts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:26</div><div class="line"></div><div class="line">scala&gt; counts.saveAsTextFile(<span class="string">"alluxio://192.168.128.91:19998/wordcount/output/spark_alluxio.output"</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 對HDFS中的文件進行測試</span></div><div class="line">scala&gt; val textFile = sc.textFile(<span class="string">"hdfs://192.168.128.91:9000/wordcount/input/page_views.dat"</span>)</div><div class="line">textFile: org.apache.spark.rdd.RDD[String] = hdfs://192.168.128.91:9000/wordcount/input/page_views.dat MapPartitionsRDD[7] at textFile at &lt;console&gt;:24</div><div class="line"></div><div class="line">scala&gt; val counts = textFile.flatMap(line =&gt; line.split(<span class="string">"\t"</span>)).map(word =&gt; (word, 1)).reduceByKey(_ + _)</div><div class="line">counts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[10] at reduceByKey at &lt;console&gt;:26</div><div class="line"></div><div class="line">scala&gt; counts.saveAsTextFile(<span class="string">"hdfs://192.168.128.91:9000/wordcount/output/spark_alluxio.output"</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>Alluxio result</p>
<img src="/2017/11/09/spark_alluxio.png" width="900"></li>
<li>Hdfs result<img src="/2017/11/09/spark_hdfs.png" width="900">
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>在小文件的作業上，Alluxio的讀入數據量與HDFS相同；在執行速度上，HDFS較優</li>
</ul>
<table>
<thead>
<tr>
<th>Platform</th>
<th>Input of Alluxio</th>
<th>Input of HDFS</th>
<th>Duration of Alluxio</th>
<th>Duration of HDFS</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hadoop</td>
<td>18.2MB</td>
<td>18.2MB</td>
<td>7s</td>
<td>4s</td>
</tr>
<tr>
<td>Spark</td>
<td>18.2MB</td>
<td>18.2MB</td>
<td>12s</td>
<td>5s</td>
</tr>
</tbody>
</table>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
            <a href="/tags/Alluxio/" rel="tag"># Alluxio</a>
          
            <a href="/tags/HDFS/" rel="tag"># HDFS</a>
          
            <a href="/tags/Spark/" rel="tag"># Spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/alluxio-instation/" rel="next" title="Alluxio Instation">
                <i class="fa fa-chevron-left"></i> Alluxio Instation
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/spark-sql-basic/" rel="prev" title="Spark SQL working with Hive">
                Spark SQL working with Hive <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="0x90e" />
            
              <p class="site-author-name" itemprop="name">0x90e</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">52</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="mailto:albertchungx90@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://github.com/0x90e" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Compere-Alluxio-with-HDFS"><span class="nav-number">1.</span> <span class="nav-text">Compere Alluxio with HDFS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Purpose"><span class="nav-number">2.</span> <span class="nav-text">Purpose</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prepare-for-Testing-File"><span class="nav-number">3.</span> <span class="nav-text">Prepare for Testing File</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-Testing"><span class="nav-number">4.</span> <span class="nav-text">Hadoop Testing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Testing"><span class="nav-number">5.</span> <span class="nav-text">Spark Testing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summary"><span class="nav-number">6.</span> <span class="nav-text">Summary</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2016 &mdash; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">0x90e</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io" rel="external nofollow">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>Unique Visitor
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>Page View
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  
  

  

  

  

</body>
</html>
