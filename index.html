<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="2318">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="2318">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="2318">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>2318</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">2318</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/25/builtin-functions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/25/builtin-functions/" itemprop="url">Hive Built-in Functions</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-25T00:03:30+08:00">
                2017-09-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hive-Built-in-Functions"><a href="#Hive-Built-in-Functions" class="headerlink" title="Hive Built-in Functions"></a>Hive Built-in Functions</h2><h3 id="Built-in-Functions"><a href="#Built-in-Functions" class="headerlink" title="Built-in Functions"></a>Built-in Functions</h3><ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-Built-inFunctions" title="Built-in Functions" target="_blank" rel="external">Apache Hive Built-in Functions</a></li>
</ul>
<h4 id="透過Hive-command列出Built-in-Functions"><a href="#透過Hive-command列出Built-in-Functions" class="headerlink" title="透過Hive command列出Built-in Functions"></a>透過Hive command列出Built-in Functions</h4><ul>
<li>顯示出當前session所支持的Built-in Functions<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">hive&gt; show functions;</div><div class="line">OK</div><div class="line">!</div><div class="line">!=</div><div class="line">%</div><div class="line">&amp;</div><div class="line">*</div><div class="line">+</div><div class="line">-</div><div class="line">/</div><div class="line">&lt;</div><div class="line">&lt;=</div><div class="line">&lt;=&gt;</div><div class="line">&lt;&gt;</div><div class="line">=</div><div class="line">==</div><div class="line">&gt;</div><div class="line">&gt;=</div><div class="line">^</div><div class="line">abs</div><div class="line">acos</div><div class="line">add_months</div><div class="line">and</div><div class="line">array</div><div class="line">array_contains</div><div class="line">ascii</div><div class="line">asin</div><div class="line">assert_true</div><div class="line">atan</div><div class="line">avg</div><div class="line"><span class="comment">-- ...</span></div><div class="line"></div><div class="line">Time taken: 0.471 seconds, Fetched: 210 row(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="查看特定Built-in-function說明。"><a href="#查看特定Built-in-function說明。" class="headerlink" title="查看特定Built-in function說明。"></a>查看特定Built-in function說明。</h4><ul>
<li>function名稱可以是show functions所顯示出來的任一個。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">hive&gt; desc function to_unix_timestamp;</div><div class="line">OK</div><div class="line">to_unix_timestamp(date[, pattern]) - Returns the UNIX timestamp</div><div class="line">Time taken: 0.084 seconds, Fetched: 1 row(s)</div><div class="line"></div><div class="line">hive&gt; desc function !;</div><div class="line">OK</div><div class="line">! a - Logical not</div><div class="line">Time taken: 0.05 seconds, Fetched: 1 row(s)</div><div class="line"></div><div class="line">hive&gt; desc function substr;</div><div class="line">OK</div><div class="line">substr(str, pos[, len]) - returns the substring of str that starts at pos and is of length len orsubstr(bin, pos[, len]) - returns the slice of byte array that starts at pos and is of length len</div><div class="line">Time taken: 0.026 seconds, Fetched: 1 row(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="顯示更詳細的Built-in-function說明"><a href="#顯示更詳細的Built-in-function說明" class="headerlink" title="顯示更詳細的Built-in function說明"></a>顯示更詳細的Built-in function說明</h4><ul>
<li>包含註釋與使用範例。</li>
<li>Synonyms關鍵字顯示，相同作用的function。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">hive&gt; desc function extended substr;</div><div class="line">OK</div><div class="line">substr(str, pos[, len]) - returns the substring of str that starts at pos and is of length len orsubstr(bin, pos[, len]) - returns the slice of byte array that starts at pos and is of length len</div><div class="line">Synonyms: substring</div><div class="line">pos is a 1-based index. If pos&lt;0 the starting position is determined by counting backwards from the end of str.</div><div class="line">Example:</div><div class="line">   &gt; SELECT substr('Facebook', 5) FROM src LIMIT 1;</div><div class="line">  'book'</div><div class="line">  &gt; SELECT substr('Facebook', -5) FROM src LIMIT 1;</div><div class="line">  'ebook'</div><div class="line">  &gt; SELECT substr('Facebook', 5, 1) FROM src LIMIT 1;</div><div class="line">  'b'</div><div class="line">Time taken: 0.028 seconds, Fetched: 10 row(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="使用Built-in-function"><a href="#使用Built-in-function" class="headerlink" title="使用Built-in function"></a>使用Built-in function</h4><ul>
<li>使用des function extented命令，可以得知此function如何使用，下述使用substr作為示例。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 列出紀錄</span></div><div class="line">hive&gt; select ename from emp limit 1;</div><div class="line">OK</div><div class="line">SMITH</div><div class="line">Time taken: 0.239 seconds, Fetched: 1 row(s)</div><div class="line"></div><div class="line"><span class="comment">-- 使用substr處理紀錄</span></div><div class="line">hive&gt; select substr(ename, 3) from emp limit 1;</div><div class="line">OK</div><div class="line">ITH</div><div class="line">Time taken: 0.119 seconds, Fetched: 1 row(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Date-Built-in-Functions"><a href="#Date-Built-in-Functions" class="headerlink" title="Date Built-in Functions"></a>Date Built-in Functions</h3><h4 id="取得當前時間"><a href="#取得當前時間" class="headerlink" title="取得當前時間"></a>取得當前時間</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">hive&gt; select to_date(from_unixtime(unix_timestamp())) from emp limit 1;</div><div class="line">OK</div><div class="line">2017-09-25</div><div class="line">Time taken: 0.083 seconds, Fetched: 1 row(s)</div><div class="line"></div><div class="line">hive&gt; select from_unixtime(unix_timestamp()) from emp limit 1;</div><div class="line">OK</div><div class="line">2017-09-25 00:11:09</div><div class="line">Time taken: 0.103 seconds, Fetched: 1 row(s)</div></pre></td></tr></table></figure>
<h4 id="取的兩個時間的天數差異"><a href="#取的兩個時間的天數差異" class="headerlink" title="取的兩個時間的天數差異"></a>取的兩個時間的天數差異</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">hive&gt; desc function extended datediff;</div><div class="line">OK</div><div class="line">datediff(date1, date2) - Returns the number of days between date1 and date2</div><div class="line">date1 and date2 are strings in the format 'yyyy-MM-dd HH:mm:ss' or 'yyyy-MM-dd'. The time parts are ignored.If date1 is earlier than date2, the result is negative.</div><div class="line">Example:</div><div class="line">   &gt; select datediff('2009-07-30', '2009-07-31') FROM src LIMIT 1;</div><div class="line">  1</div><div class="line">Time taken: 0.011 seconds, Fetched: 5 row(s)</div><div class="line"></div><div class="line"><span class="comment">-- 使用datediff函數，輸入格式為yyyy-MM-dd</span></div><div class="line">hive&gt; select datediff('2010-07-31', '2009-07-31') from emp limit 1;</div><div class="line">OK</div><div class="line">365</div><div class="line">Time taken: 0.045 seconds, Fetched: 1 row(s)</div><div class="line"></div><div class="line"><span class="comment">-- 使用datediff函數，輸入格式為yyyy-MM-dd HH:mm:ss</span></div><div class="line">hive&gt; select datediff('2010-07-31 10:20:00', '2009-07-31 11:21:00') FROM emp LIMIT 1;</div><div class="line">OK</div><div class="line">365</div><div class="line">Time taken: 0.047 seconds, Fetched: 1 row(s)</div></pre></td></tr></table></figure>
<h3 id="Type-Conversion-Functions"><a href="#Type-Conversion-Functions" class="headerlink" title="Type Conversion Functions"></a>Type Conversion Functions</h3><ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-TypeConversionFunctions" title="Type Conversion Functions" target="_blank" rel="external">Apache Hive Type Conversion Functions</a></li>
</ul>
<h4 id="使用Type-Conversion-Functions"><a href="#使用Type-Conversion-Functions" class="headerlink" title="使用Type Conversion Functions"></a>使用Type Conversion Functions</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">hive&gt; desc emp;</div><div class="line">OK</div><div class="line">empno               	int</div><div class="line">ename               	string</div><div class="line">job                 	string</div><div class="line">mgr                 	int</div><div class="line">hiredate            	string</div><div class="line">sal                 	double</div><div class="line">comm                	double</div><div class="line">deptno              	int</div><div class="line">Time taken: 0.164 seconds, Fetched: 8 row(s)</div><div class="line"></div><div class="line"><span class="comment">-- 將double類型的sal紀錄，轉換成int類型</span></div><div class="line">hive&gt; select sal, cast(sal as int) from emp;</div><div class="line">OK</div><div class="line">800.0	800</div><div class="line">1600.0	1600</div><div class="line">1250.0	1250</div><div class="line">2975.0	2975</div><div class="line">1250.0	1250</div><div class="line">2850.0	2850</div><div class="line">2450.0	2450</div><div class="line">3000.0	3000</div><div class="line">5000.0	5000</div><div class="line">1500.0	1500</div><div class="line">1100.0	1100</div><div class="line">950.0	950</div><div class="line">3000.0	3000</div><div class="line">1300.0	1300</div><div class="line">10300.0	10300</div><div class="line">Time taken: 0.082 seconds, Fetched: 15 row(s)</div></pre></td></tr></table></figure>
<h4 id="Type-Conversion-Failure"><a href="#Type-Conversion-Failure" class="headerlink" title="Type Conversion Failure"></a>Type Conversion Failure</h4><ul>
<li>當轉換失敗時，Type Conversion Function將會回傳NUll<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">hive&gt; select ename, cast(ename as int) from emp;</div><div class="line">OK</div><div class="line">SMITH	NULL</div><div class="line">ALLEN	NULL</div><div class="line">WARD	NULL</div><div class="line">JONES	NULL</div><div class="line">MARTIN	NULL</div><div class="line">BLAKE	NULL</div><div class="line">CLARK	NULL</div><div class="line">SCOTT	NULL</div><div class="line">KING	NULL</div><div class="line">TURNER	NULL</div><div class="line">ADAMS	NULL</div><div class="line">JAMES	NULL</div><div class="line">FORD	NULL</div><div class="line">MILLER	NULL</div><div class="line">HIVE	NULL</div><div class="line">Time taken: 0.088 seconds, Fetched: 15 row(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Binary-Type-Conversion"><a href="#Binary-Type-Conversion" class="headerlink" title="Binary Type Conversion"></a>Binary Type Conversion</h4><ul>
<li>若Binary要轉成Int類型，須先轉換成String類型，才能換成Int類型。</li>
</ul>
<h3 id="常用built-in-functions補充"><a href="#常用built-in-functions補充" class="headerlink" title="常用built-in functions補充"></a>常用built-in functions補充</h3><h4 id="isnull-and-isnotnull"><a href="#isnull-and-isnotnull" class="headerlink" title="isnull and isnotnull"></a>isnull and isnotnull</h4><ul>
<li>isnull: 若紀錄為null，則回傳true。</li>
<li>isnotnull: 與isnull相反。若紀錄不為null，則回傳true。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">hive&gt; select comm, isnull(comm), isnotnull(comm) from emp;</div><div class="line">OK</div><div class="line">NULL	true	false</div><div class="line">300.0	false	true</div><div class="line">500.0	false	true</div><div class="line">NULL	true	false</div><div class="line">1400.0	false	true</div><div class="line">NULL	true	false</div><div class="line">NULL	true	false</div><div class="line">NULL	true	false</div><div class="line">NULL	true	false</div><div class="line">0.0	false	true</div><div class="line">NULL	true	false</div><div class="line">NULL	true	false</div><div class="line">NULL	true	false</div><div class="line">NULL	true	false</div><div class="line">NULL	true	false</div><div class="line">Time taken: 0.079 seconds, Fetched: 15 row(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="assert-true"><a href="#assert-true" class="headerlink" title="assert_true"></a>assert_true</h4><ul>
<li>判斷指定欄位內的紀錄中，若有任何一個紀錄不符合，則拋出異常。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">hive&gt; select assert_true(sal &gt; 700) from emp;</div><div class="line">OK</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">NULL</div><div class="line">Time taken: 0.096 seconds, Fetched: 15 row(s)</div><div class="line"></div><div class="line">hive&gt; select assert_true(sal &gt; 800) from emp;</div><div class="line">OK</div><div class="line">Failed with exception java.io.IOException:org.apache.hadoop.hive.ql.metadata.HiveException: ASSERT_TRUE(): assertion failed.</div><div class="line">Time taken: 0.07 seconds</div></pre></td></tr></table></figure>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/24/hive-join/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/24/hive-join/" itemprop="url">Hive Join</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-24T14:17:48+08:00">
                2017-09-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hive-Join"><a href="#Hive-Join" class="headerlink" title="Hive Join"></a>Hive Join</h2><h3 id="Hive中的Join的用法"><a href="#Hive中的Join的用法" class="headerlink" title="Hive中的Join的用法"></a>Hive中的Join的用法</h3><h4 id="創建join示例所使用的表。"><a href="#創建join示例所使用的表。" class="headerlink" title="創建join示例所使用的表。"></a>創建join示例所使用的表。</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 創建table a </span></div><div class="line">hive&gt; create table a(</div><div class="line">    id int,</div><div class="line">    name string</div><div class="line">    )row format delimited fields terminated by '\t';</div><div class="line">OK</div><div class="line"></div><div class="line"><span class="comment">-- 從本地文件載入資料</span></div><div class="line">hive&gt; load data local inpath '/home/hadoop/data/a_join.txt' into table a;</div><div class="line">Loading data to table default.a</div><div class="line">Table default.a stats: [numFiles=1, totalSize=26]</div><div class="line">OK</div><div class="line">Time taken: 0.293 seconds</div><div class="line"></div><div class="line"></div><div class="line">hive&gt; select * from a;</div><div class="line">OK</div><div class="line">1	zhangsa</div><div class="line">2	lisi</div><div class="line">3	wangwu</div><div class="line">Time taken: 0.055 seconds, Fetched: 3 row(s)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">-- 創建table b</span></div><div class="line">hive&gt; create table b(</div><div class="line">    id int,</div><div class="line">    age int</div><div class="line">    ) row format delimited fields terminated by '\t';</div><div class="line">OK</div><div class="line"></div><div class="line"><span class="comment">-- 從本地文件載入資料</span></div><div class="line">hive&gt; load data local inpath '/home/hadoop/data/b_join.txt' into table b;</div><div class="line">Loading data to table default.b</div><div class="line">Table default.b stats: [numFiles=1, totalSize=15]</div><div class="line">OK</div><div class="line">Time taken: 0.241 seconds</div><div class="line"></div><div class="line"></div><div class="line">hive&gt; select * from b;</div><div class="line">OK</div><div class="line">1	28</div><div class="line">2	19</div><div class="line">4	21</div><div class="line">Time taken: 0.089 seconds, Fetched: 3 row(s)</div></pre></td></tr></table></figure>
<h4 id="Inner-Join"><a href="#Inner-Join" class="headerlink" title="Inner Join"></a>Inner Join</h4><ul>
<li>只返回能關聯的紀錄。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">hive&gt; select a.id, a.name, b.age from a join b on a.id=b.id;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">17/09/16 17:37:52 WARN util.NativeCodeLoader: Unable to <span class="keyword">load</span> <span class="keyword">native</span>-hadoop <span class="keyword">library</span> <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-<span class="keyword">java</span> classes <span class="keyword">where</span> applicable</div><div class="line">Execution <span class="keyword">log</span> <span class="keyword">at</span>: /opt/software/hive/<span class="keyword">log</span>/hadoop_20170914014141_a03e8794<span class="number">-0</span>c51<span class="number">-414</span>f<span class="number">-87</span>d7<span class="number">-50236e8</span>e1b36.log</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">05</span>:<span class="number">37</span>:<span class="number">53</span>	<span class="keyword">Starting</span> <span class="keyword">to</span> launch <span class="keyword">local</span> task <span class="keyword">to</span> process <span class="keyword">map</span> <span class="keyword">join</span>;	maximum memory = 518979584</div><div class="line">2017-09-16 05:37:55	Dump the side-table for tag: 1 with group count: 3 into file: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-37-49_384_3178169469256003866-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile11<span class="comment">--.hashtable</span></div><div class="line">2017-09-16 05:37:55	Uploaded 1 File to: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-37-49_384_3178169469256003866-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile11<span class="comment">--.hashtable (320 bytes)</span></div><div class="line">2017-09-16 05:37:55	<span class="keyword">End</span> <span class="keyword">of</span> <span class="keyword">local</span> task; Time Taken: 2.002 sec.</div><div class="line">Execution completed successfully</div><div class="line">MapredLocal task succeeded</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since theres <span class="keyword">no</span> reduce <span class="keyword">operator</span></div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">17</span>:<span class="number">37</span>:<span class="number">56</span>,<span class="number">968</span> Stage<span class="number">-3</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">0</span>%</div><div class="line">Ended Job = job_local1965457212_0036</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-3</span>:  HDFS <span class="keyword">Read</span>: <span class="number">55888</span> HDFS Write: <span class="number">10506</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">1</span>	zhangsa	<span class="number">28</span></div><div class="line"><span class="number">2</span>	lisi	<span class="number">19</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">7.589</span> seconds, Fetched: <span class="number">2</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Left-Join"><a href="#Left-Join" class="headerlink" title="Left Join"></a>Left Join</h4><ul>
<li>使用左表作為主表，返回紀錄數與左表相同。</li>
<li>關聯不上的使用NULL表示。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">hive&gt; select a.id, a.name, b.age from a left join b on a.id=b.id;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">17/09/16 17:39:46 WARN util.NativeCodeLoader: Unable to <span class="keyword">load</span> <span class="keyword">native</span>-hadoop <span class="keyword">library</span> <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-<span class="keyword">java</span> classes <span class="keyword">where</span> applicable</div><div class="line">Execution <span class="keyword">log</span> <span class="keyword">at</span>: /opt/software/hive/<span class="keyword">log</span>/hadoop_20170914014141_a03e8794<span class="number">-0</span>c51<span class="number">-414</span>f<span class="number">-87</span>d7<span class="number">-50236e8</span>e1b36.log</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">05</span>:<span class="number">39</span>:<span class="number">47</span>	<span class="keyword">Starting</span> <span class="keyword">to</span> launch <span class="keyword">local</span> task <span class="keyword">to</span> process <span class="keyword">map</span> <span class="keyword">join</span>;	maximum memory = 518979584</div><div class="line">2017-09-16 05:39:48	Dump the side-table for tag: 1 with group count: 3 into file: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-39-43_925_9210396379212280287-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile21<span class="comment">--.hashtable</span></div><div class="line">2017-09-16 05:39:48	Uploaded 1 File to: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-39-43_925_9210396379212280287-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile21<span class="comment">--.hashtable (320 bytes)</span></div><div class="line">2017-09-16 05:39:48	<span class="keyword">End</span> <span class="keyword">of</span> <span class="keyword">local</span> task; Time Taken: 0.912 sec.</div><div class="line">Execution completed successfully</div><div class="line">MapredLocal task succeeded</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since theres <span class="keyword">no</span> reduce <span class="keyword">operator</span></div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">17</span>:<span class="number">39</span>:<span class="number">50</span>,<span class="number">005</span> Stage<span class="number">-3</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">0</span>%</div><div class="line">Ended Job = job_local296218704_0037</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-3</span>:  HDFS <span class="keyword">Read</span>: <span class="number">55914</span> HDFS Write: <span class="number">10506</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">1</span>	zhangsa	<span class="number">28</span></div><div class="line"><span class="number">2</span>	lisi	<span class="number">19</span></div><div class="line"><span class="number">3</span>	wangwu	<span class="literal">NULL</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">6.09</span> seconds, Fetched: <span class="number">3</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Right-Join"><a href="#Right-Join" class="headerlink" title="Right Join"></a>Right Join</h4><ul>
<li>使用右表作為主表，返回紀錄數與右表相同。</li>
<li>關聯不上的使用NULL表示。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">hive&gt; select a.id, a.name, b.age from a right join b on a.id=b.id;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">17/09/16 17:40:40 WARN util.NativeCodeLoader: Unable to <span class="keyword">load</span> <span class="keyword">native</span>-hadoop <span class="keyword">library</span> <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-<span class="keyword">java</span> classes <span class="keyword">where</span> applicable</div><div class="line">Execution <span class="keyword">log</span> <span class="keyword">at</span>: /opt/software/hive/<span class="keyword">log</span>/hadoop_20170914014141_a03e8794<span class="number">-0</span>c51<span class="number">-414</span>f<span class="number">-87</span>d7<span class="number">-50236e8</span>e1b36.log</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">05</span>:<span class="number">40</span>:<span class="number">41</span>	<span class="keyword">Starting</span> <span class="keyword">to</span> launch <span class="keyword">local</span> task <span class="keyword">to</span> process <span class="keyword">map</span> <span class="keyword">join</span>;	maximum memory = 518979584</div><div class="line">2017-09-16 05:40:42	Dump the side-table for tag: 0 with group count: 3 into file: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-40-37_662_8266497628801648044-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile30<span class="comment">--.hashtable</span></div><div class="line">2017-09-16 05:40:42	Uploaded 1 File to: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-40-37_662_8266497628801648044-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile30<span class="comment">--.hashtable (337 bytes)</span></div><div class="line">2017-09-16 05:40:42	<span class="keyword">End</span> <span class="keyword">of</span> <span class="keyword">local</span> task; Time Taken: 1.125 sec.</div><div class="line">Execution completed successfully</div><div class="line">MapredLocal task succeeded</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since theres <span class="keyword">no</span> reduce <span class="keyword">operator</span></div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">17</span>:<span class="number">40</span>:<span class="number">43</span>,<span class="number">702</span> Stage<span class="number">-3</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">0</span>%</div><div class="line">Ended Job = job_local2139900301_0038</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-3</span>:  HDFS <span class="keyword">Read</span>: <span class="number">55929</span> HDFS Write: <span class="number">10506</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">1</span>	zhangsa	<span class="number">28</span></div><div class="line"><span class="number">2</span>	lisi	<span class="number">19</span></div><div class="line"><span class="literal">NULL</span>	<span class="literal">NULL</span>	<span class="number">21</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">6.042</span> seconds, Fetched: <span class="number">3</span> <span class="keyword">row</span>(s)</div><div class="line"><span class="comment">-- 最後一列的id為null而不是為4，是因為select語句中，是取用table a的id，而不是table b的id。</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Full-Join"><a href="#Full-Join" class="headerlink" title="Full Join"></a>Full Join</h4><ul>
<li>以兩個表的紀錄為基準，返回兩個表的紀錄去重之和。</li>
<li>關聯不上的使用NULL表示。</li>
<li>在此情況下，Hive不使用Map Join來優化。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">hive&gt; select a.id, a.name, b.age from a full join b on a.id=b.id;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks not specified. Estimated from input data size: 1</div><div class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">17</span>:<span class="number">42</span>:<span class="number">15</span>,<span class="number">465</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">0</span>%,  reduce = <span class="number">0</span>%</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">17</span>:<span class="number">42</span>:<span class="number">16</span>,<span class="number">467</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</div><div class="line">Ended Job = job_local1292867757_0039</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">167895</span> HDFS Write: <span class="number">31518</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">1</span>	zhangsa	<span class="number">28</span></div><div class="line"><span class="number">2</span>	lisi	<span class="number">19</span></div><div class="line"><span class="number">3</span>	wangwu	<span class="literal">NULL</span></div><div class="line"><span class="literal">NULL</span>	<span class="literal">NULL</span>	<span class="number">21</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">2.285</span> seconds, Fetched: <span class="number">4</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Cross-Join"><a href="#Cross-Join" class="headerlink" title="Cross Join"></a>Cross Join</h4><ul>
<li>返回兩個表的笛卡兒積(Cartesian product)結果</li>
<li>不需指定關聯鍵，及不需使用on關鍵字。<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">hive&gt; select a.id, a.name, b.age from a cross join b;</div><div class="line">Warning: Map Join MAPJOIN[7][bigTable=a] in task 'Stage-3:MAPRED' is a cross product</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">17/09/16 17:44:22 WARN util.NativeCodeLoader: Unable to <span class="keyword">load</span> <span class="keyword">native</span>-hadoop <span class="keyword">library</span> <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-<span class="keyword">java</span> classes <span class="keyword">where</span> applicable</div><div class="line">Execution <span class="keyword">log</span> <span class="keyword">at</span>: /opt/software/hive/<span class="keyword">log</span>/hadoop_20170914014141_a03e8794<span class="number">-0</span>c51<span class="number">-414</span>f<span class="number">-87</span>d7<span class="number">-50236e8</span>e1b36.log</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">05</span>:<span class="number">44</span>:<span class="number">23</span>	<span class="keyword">Starting</span> <span class="keyword">to</span> launch <span class="keyword">local</span> task <span class="keyword">to</span> process <span class="keyword">map</span> <span class="keyword">join</span>;	maximum memory = 518979584</div><div class="line">2017-09-16 05:44:23	Dump the side-table for tag: 1 with group count: 1 into file: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-44-19_720_6308228100696237254-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile51<span class="comment">--.hashtable</span></div><div class="line">2017-09-16 05:44:24	Uploaded 1 File to: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_17-44-19_720_6308228100696237254-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile51<span class="comment">--.hashtable (290 bytes)</span></div><div class="line">2017-09-16 05:44:24	<span class="keyword">End</span> <span class="keyword">of</span> <span class="keyword">local</span> task; Time Taken: 0.961 sec.</div><div class="line">Execution completed successfully</div><div class="line">MapredLocal task succeeded</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since theres <span class="keyword">no</span> reduce <span class="keyword">operator</span></div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">17</span>:<span class="number">44</span>:<span class="number">25</span>,<span class="number">491</span> Stage<span class="number">-3</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">0</span>%</div><div class="line">Ended Job = job_local1992175647_0041</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-3</span>:  HDFS <span class="keyword">Read</span>: <span class="number">56022</span> HDFS Write: <span class="number">10506</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">1</span>	zhangsa	<span class="number">28</span></div><div class="line"><span class="number">1</span>	zhangsa	<span class="number">19</span></div><div class="line"><span class="number">1</span>	zhangsa	<span class="number">21</span></div><div class="line"><span class="number">2</span>	lisi	<span class="number">28</span></div><div class="line"><span class="number">2</span>	lisi	<span class="number">19</span></div><div class="line"><span class="number">2</span>	lisi	<span class="number">21</span></div><div class="line"><span class="number">3</span>	wangwu	<span class="number">28</span></div><div class="line"><span class="number">3</span>	wangwu	<span class="number">19</span></div><div class="line"><span class="number">3</span>	wangwu	<span class="number">21</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">5.781</span> seconds, Fetched: <span class="number">9</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Hive-join"><a href="#Hive-join" class="headerlink" title="Hive join"></a>Hive join</h3><ul>
<li>Hive中的join，分成下列兩種:<ul>
<li>Common join: 又稱Shuffle join、Reduce join </li>
<li>Map join: 又稱Broadcast join</li>
</ul>
</li>
<li>hive-site.xml相關屬性:</li>
</ul>
<table>
<thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>hive.auto.convert.join</td>
<td>是否轉換為Map Join</td>
<td>false in 0.7.0 to 0.10.0; true in 0.11.0 and later</td>
</tr>
<tr>
<td>hive.mapjoin.smalltable.filesize</td>
<td>判斷為小表的上限依據</td>
<td>25MB</td>
</tr>
<tr>
<td>hive.auto.convert.join.noconditionaltask</td>
<td>是否將多個Map join合併為一個</td>
<td>true</td>
</tr>
<tr>
<td>hive.auto.convert.join.noconditionaltask.size</td>
<td>多個Map join轉換為1個時，所有小表文件大小總和的最大值</td>
<td>10MB</td>
</tr>
</tbody>
</table>
<h4 id="Common-Join"><a href="#Common-Join" class="headerlink" title="Common Join"></a>Common Join</h4><img src="/2017/09/24/hive-join/hive_normal_join.svg" width="600">
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 此屬性預設為true，若要啟動Common Join需先設定為false</span></div><div class="line">hive&gt; set hive.auto.convert.join=false;</div><div class="line">hive&gt; set hive.auto.convert.join;</div><div class="line">hive.auto.convert.join=false</div><div class="line"></div><div class="line"><span class="comment">-- 顯示查詢語句的執行計畫</span></div><div class="line">hive&gt; explain select a.id, a.name, b.age from a join b on a.id=b.id;</div><div class="line">OK</div><div class="line">STAGE DEPENDENCIES:</div><div class="line">  Stage-1 is a root stage</div><div class="line">  Stage-0 depends on stages: Stage-1</div><div class="line"></div><div class="line">STAGE PLANS:</div><div class="line">  Stage: Stage-1</div><div class="line">    Map Reduce</div><div class="line">      Map Operator Tree:</div><div class="line">          TableScan</div><div class="line">            alias: a</div><div class="line">            Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div><div class="line">            Filter Operator</div><div class="line">              predicate: id is not null (type: boolean)</div><div class="line">              Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div><div class="line">              Reduce Output Operator</div><div class="line">                key expressions: id (type: int)</div><div class="line">                sort order: +</div><div class="line">                Map-reduce partition columns: id (type: int)</div><div class="line">                Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div><div class="line">                value expressions: name (type: string)</div><div class="line">          TableScan</div><div class="line">            alias: b</div><div class="line">            Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</div><div class="line">            Filter Operator</div><div class="line">              predicate: id is not null (type: boolean)</div><div class="line">              Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</div><div class="line">              Reduce Output Operator</div><div class="line">                key expressions: id (type: int)</div><div class="line">                sort order: +</div><div class="line">                Map-reduce partition columns: id (type: int)</div><div class="line">                Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</div><div class="line">                value expressions: age (type: int)</div><div class="line">      Reduce Operator Tree:</div><div class="line">        Join Operator</div><div class="line">          condition map:</div><div class="line">               Inner Join 0 to 1</div><div class="line">          keys:</div><div class="line">            0 id (type: int)</div><div class="line">            1 id (type: int)</div><div class="line">          outputColumnNames: _col0, _col1, _col6</div><div class="line">          Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</div><div class="line">          <span class="keyword">Select</span> <span class="keyword">Operator</span></div><div class="line">            expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">int</span>), _col1 (<span class="keyword">type</span>: <span class="keyword">string</span>), _col6 (<span class="keyword">type</span>: <span class="built_in">int</span>)</div><div class="line">            outputColumnNames: _col0, _col1, _col2</div><div class="line">            <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">28</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></div><div class="line">            <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Operator</span></div><div class="line">              compressed: <span class="literal">false</span></div><div class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">28</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></div><div class="line">              <span class="keyword">table</span>:</div><div class="line">                  <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</div><div class="line">                  <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</div><div class="line">                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</div><div class="line"></div><div class="line">  Stage: Stage<span class="number">-0</span></div><div class="line">    <span class="keyword">Fetch</span> <span class="keyword">Operator</span></div><div class="line">      <span class="keyword">limit</span>: <span class="number">-1</span></div><div class="line">      Processor Tree:</div><div class="line">        ListSink</div><div class="line"></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">0.138</span> seconds, Fetched: <span class="number">59</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
<h5 id="執行計畫說明"><a href="#執行計畫說明" class="headerlink" title="執行計畫說明"></a>執行計畫說明</h5><p>上面為Common Join的執行計畫，下面將分段解釋所代表意思。</p>
<ul>
<li>共生成2個Stage，且需要先執行完Stage-1，才能執行Stage-0。</li>
<li>Stage-1區段中的Mapreduce關鍵字說明此為一個MapReduece Job，分別描述在Map Operator Tree與Reduce Operator Tree區段。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Map Operator Tree:</div><div class="line">    TableScan</div><div class="line">      alias: a</div><div class="line">      Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div><div class="line">      Filter Operator</div><div class="line">        predicate: id is not null (type: boolean)</div><div class="line">        Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div></pre></td></tr></table></figure>
<ul>
<li>Map Operator Tree<ul>
<li>TableScan: 進行讀表操作。</li>
<li>alias: 目標表的名稱。</li>
<li>Statistics: 讀入數據的相關資訊。</li>
<li>Filter Operator: 雖然SQL語句中不包含Where，但是join語句中隱藏一個過濾條件(on關鍵字)。<ul>
<li>predicate: join條件。</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Reduce Output Operator</div><div class="line">  key expressions: id (type: int)</div><div class="line">  sort order: +</div><div class="line">  Map-reduce partition columns: id (type: int)</div><div class="line">  Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div><div class="line">  value expressions: name (type: string)</div></pre></td></tr></table></figure>
<ul>
<li>Reduce Output Operator<ul>
<li>及為Mapper的輸出。</li>
<li>key expressions: 對應join語句中on的對象。</li>
<li>value expressions:value是一系列的字段，對應select語句。</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">Reduce Operator Tree:</div><div class="line">  Join Operator</div><div class="line">    condition map:</div><div class="line">         Inner Join 0 to 1</div><div class="line">    keys:</div><div class="line">      0 id (type: int)</div><div class="line">      1 id (type: int)</div><div class="line">    outputColumnNames: _col0, _col1, _col6</div><div class="line">    Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</div><div class="line">    <span class="keyword">Select</span> <span class="keyword">Operator</span></div><div class="line">      expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">int</span>), _col1 (<span class="keyword">type</span>: <span class="keyword">string</span>), _col6 (<span class="keyword">type</span>: <span class="built_in">int</span>)</div><div class="line">      outputColumnNames: _col0, _col1, _col2</div><div class="line">      <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">28</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></div><div class="line">      <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Operator</span></div><div class="line">        compressed: <span class="literal">false</span></div><div class="line">        <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">28</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></div><div class="line">        <span class="keyword">table</span>:</div><div class="line">            <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</div><div class="line">            <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</div><div class="line">            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</div></pre></td></tr></table></figure>
<ul>
<li>Reduce Operator<ul>
<li>Inner Join 0 to 1: 此為一個inner join操作。</li>
<li>keys: join操作時，各表所使用的的key。</li>
<li>Select Operator: reduce結果輸出的相關訊息。<ul>
<li>compressed: 是否使用壓縮。</li>
<li>Statistics: 輸出數據的相關統計訊息。</li>
<li>input/output format: 輸出入檔案的格式。</li>
<li>serde: 序列化物件。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="小結"><a href="#小結" class="headerlink" title="小結"></a>小結</h5><p>上面為Common Join的流程圖以及執行計畫說明，在MapReduce的執行common join過程中，需要Shuffle進行重新洗牌的操作，也就是將key進行Hash處理後相同的值，放置在一塊，作為Reduce的輸入。這個過程中如果傳輸的量很大會造成一定的網路資源開銷，且可能造成OOM的問題，導致計算任務失敗。<br>若Shuffle是計算瓶頸所在，而Shuffle是為Reduce的前置作業，如何去除掉Shuffle，又能達到Reduce的結果。故Map Join就是用來解決此問題。</p>
<h4 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h4><img src="/2017/09/24/hive-join/hive_mapjoin.svg" width="400">
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 將此屬性設為true，啟用Map Join</span></div><div class="line">hive&gt; set hive.auto.convert.join=true;</div><div class="line">hive&gt; set hive.auto.convert.join;</div><div class="line">hive.auto.convert.join=true</div><div class="line"></div><div class="line">hive&gt; explain select a.id, a.name, b.age from a join b on a.id=b.id;</div><div class="line">OK</div><div class="line">STAGE DEPENDENCIES:</div><div class="line">  Stage-4 is a root stage</div><div class="line">  Stage-3 depends on stages: Stage-4</div><div class="line">  Stage-0 depends on stages: Stage-3</div><div class="line"></div><div class="line">STAGE PLANS:</div><div class="line">  Stage: Stage-4</div><div class="line">    Map Reduce Local Work</div><div class="line">      Alias -&gt; Map Local Tables:</div><div class="line">        b </div><div class="line">          Fetch Operator</div><div class="line">            limit: -1</div><div class="line">      Alias -&gt; Map Local Operator Tree:</div><div class="line">        b </div><div class="line">          TableScan</div><div class="line">            alias: b</div><div class="line">            Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</div><div class="line">            Filter Operator</div><div class="line">              predicate: id is not null (type: boolean)</div><div class="line">              Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</div><div class="line">              HashTable Sink Operator</div><div class="line">                keys:</div><div class="line">                  0 id (type: int)</div><div class="line">                  1 id (type: int)</div><div class="line"></div><div class="line">  Stage: Stage-3</div><div class="line">    Map Reduce</div><div class="line">      Map Operator Tree:</div><div class="line">          TableScan</div><div class="line">            alias: a</div><div class="line">            Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div><div class="line">            Filter Operator</div><div class="line">              predicate: id is not null (type: boolean)</div><div class="line">              Statistics: Num rows: 1 Data size: 26 Basic stats: COMPLETE Column stats: NONE</div><div class="line">              Map Join Operator</div><div class="line">                condition map:</div><div class="line">                     Inner Join 0 to 1</div><div class="line">                keys:</div><div class="line">                  0 id (type: int)</div><div class="line">                  1 id (type: int)</div><div class="line">                outputColumnNames: _col0, _col1, _col6</div><div class="line">                Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</div><div class="line">                <span class="keyword">Select</span> <span class="keyword">Operator</span></div><div class="line">                  expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">int</span>), _col1 (<span class="keyword">type</span>: <span class="keyword">string</span>), _col6 (<span class="keyword">type</span>: <span class="built_in">int</span>)</div><div class="line">                  outputColumnNames: _col0, _col1, _col2</div><div class="line">                  <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">28</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></div><div class="line">                  <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Operator</span></div><div class="line">                    compressed: <span class="literal">false</span></div><div class="line">                    <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">28</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></div><div class="line">                    <span class="keyword">table</span>:</div><div class="line">                        <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</div><div class="line">                        <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</div><div class="line">                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</div><div class="line">      <span class="keyword">Local</span> <span class="keyword">Work</span>:</div><div class="line">        <span class="keyword">Map</span> Reduce <span class="keyword">Local</span> <span class="keyword">Work</span></div><div class="line"></div><div class="line">  Stage: Stage<span class="number">-0</span></div><div class="line">    <span class="keyword">Fetch</span> <span class="keyword">Operator</span></div><div class="line">      <span class="keyword">limit</span>: <span class="number">-1</span></div><div class="line">      Processor Tree:</div><div class="line">        ListSink</div><div class="line"></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">0.16</span> seconds, Fetched: <span class="number">62</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
<h5 id="執行計畫說明-1"><a href="#執行計畫說明-1" class="headerlink" title="執行計畫說明"></a>執行計畫說明</h5><p>上面為Map Join的執行計畫，下面將分段解釋所代表意思。</p>
<ul>
<li>此執行計畫共分成3個Stage，依次為Stage-4、Stage-3、Stage-0，且由後往前為依賴關係，需要先執行完Stage-4，才能執行Stage-3，最後執行Stage-0。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">Map Reduce Local Work</div><div class="line">  Alias -&gt; Map Local Tables:</div><div class="line">    b </div><div class="line">      Fetch Operator</div><div class="line">        limit: -1</div><div class="line">  Alias -&gt; Map Local Operator Tree:</div><div class="line">    b </div><div class="line">      TableScan</div><div class="line">        alias: b</div><div class="line">        Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</div><div class="line">        Filter Operator</div><div class="line">          predicate: id is not null (type: boolean)</div><div class="line">          Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</div><div class="line">          HashTable Sink Operator</div><div class="line">            keys:</div><div class="line">              0 id (type: int)</div></pre></td></tr></table></figure>
<ul>
<li>Map Reduce Local Work: 啟動一個MapReduce Local Task。對應圖中的MapReduce Local Task方框。</li>
<li>TableScan<ul>
<li>alias: b: 根據MetaData中的統計訊息自動決定b表為小表，並且進行讀入數據。</li>
<li>HashTable Sink Operator: 輸出HashTable並存到HDFS上，對應圖中的HashTable File。</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Stage: Stage-3</div><div class="line">  Map Reduce</div><div class="line">    Map Operator Tree:</div></pre></td></tr></table></figure>
<ul>
<li>Stage: Stage-3: 為一個MapReduce Job，但其只包含Map Task，並將計算結果輸出至HDFS上。</li>
</ul>
<h5 id="小結-1"><a href="#小結-1" class="headerlink" title="小結"></a>小結</h5><ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization" title="JoinOptimization" target="_blank" rel="external">官方文檔 JoinOptimization</a></li>
<li>上圖為Map Join的流程圖以及執行計畫，Map Join會將小表全部讀入記憶體中，並產生HashTable檔案，接著將HashTable加載到分布式緩存中。在map階段，直接拿HashTable與大表中的紀錄做匹配。</li>
<li>由於在map中進行了join的操作，省去了shuffle與reduce的過程，執行效率提高很多，並且省去Shuffle階段要進行的大量資料傳輸，達成優化作業的作用。</li>
<li>使用Map Join時要注意小表的大小，因為會將小表全部寫入分布式記憶體中，故當所需記憶體過大時，會發生OOM。而小表的上限判定值，可以根據屬性來設定。</li>
<li>要使Map Join能夠順利進行，必須滿足: 除了一份表的資料分佈在不同的Map中之外，其他連接的表的資料必須在每個Map中有完整的複製。</li>
</ul>
<h3 id="Hive-log"><a href="#Hive-log" class="headerlink" title="Hive log"></a>Hive log</h3><ul>
<li>查看執行Common join跟Map Join對應的Hive Log。</li>
<li>Hive Log的位置在$HIVE_HOME/conf/hive-log4j.properties中的以下參數設定:<ul>
<li>hive.log.dir=${java.io.tmpdir}/${user.name}</li>
<li>hive.log.file=hive.log</li>
</ul>
</li>
</ul>
<h4 id="Common-Join-Log"><a href="#Common-Join-Log" class="headerlink" title="Common Join Log"></a>Common Join Log</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">2017-09-23 18:01:03,204 INFO  [main]: ql.Driver (Driver.java:compile(411)) - Compiling <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56): select a.id, a.name, b.age from a join b on a.id=b.id</div><div class="line">2017-09-23 18:01:03,334 INFO  [main]: ql.Driver (Driver.java:compile(463)) - Semantic Analysis Completed</div><div class="line">2017-09-23 18:01:03,334 INFO  [main]: ql.Driver (Driver.java:getSchema(245)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:a.id, <span class="built_in">type</span>:int, comment:null), FieldSchema(name:a.name, <span class="built_in">type</span>:string, comment:null), FieldSchema(name:b.age, <span class="built_in">type</span>:int, comment:null)], properties:null)</div><div class="line">2017-09-23 18:01:03,345 INFO  [main]: ql.Driver (Driver.java:compile(541)) - Completed compiling <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56); Time taken: 0.141 seconds</div><div class="line">2017-09-23 18:01:03,346 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(165)) - Concurrency mode is disabled, not creating a lock manager</div><div class="line">2017-09-23 18:01:03,346 INFO  [main]: ql.Driver (Driver.java:execute(1448)) - Executing <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56): select a.id, a.name, b.age from a join b on a.id=b.id</div><div class="line">2017-09-23 18:01:03,346 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Query ID = hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56</div><div class="line">2017-09-23 18:01:03,347 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Total <span class="built_in">jobs</span> = 1</div><div class="line">2017-09-23 18:01:03,347 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Launching Job 1 out of 1</div><div class="line">2017-09-23 18:01:03,351 INFO  [main]: ql.Driver (Driver.java:launchTask(1772)) - Starting task [Stage-1:MAPRED] <span class="keyword">in</span> serial mode</div><div class="line">2017-09-23 18:01:03,354 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Number of reduce tasks not specified. Estimated from input data size: 1</div><div class="line">2017-09-23 18:01:03,354 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - In order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</div><div class="line">2017-09-23 18:01:03,355 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) -   <span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</div><div class="line">2017-09-23 18:01:03,355 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - In order to <span class="built_in">limit</span> the maximum number of reducers:</div><div class="line">2017-09-23 18:01:03,355 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) -   <span class="built_in">set</span> hive.exec.reducers.max=&lt;number&gt;</div><div class="line">2017-09-23 18:01:03,355 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - In order to <span class="built_in">set</span> a constant number of reducers:</div><div class="line">2017-09-23 18:01:03,356 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) -   <span class="built_in">set</span> mapreduce.job.reduces=&lt;number&gt;</div><div class="line">2017-09-23 18:01:03,357 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(286)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</div><div class="line">2017-09-23 18:01:03,357 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(308)) - adding libjars: file:///opt/software/hive/auxlib/com.hive.demo-1.0.jar</div><div class="line">2017-09-23 18:01:03,382 ERROR [main]: mr.ExecDriver (ExecDriver.java:execute(398)) - <span class="built_in">local</span></div><div class="line">2017-09-23 18:01:03,399 WARN  [main]: mapreduce.JobResourceUploader (JobResourceUploader.java:uploadFiles(64)) - Hadoop <span class="built_in">command</span>-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.</div><div class="line">2017-09-23 18:01:03,741 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Job running <span class="keyword">in</span>-process (<span class="built_in">local</span> Hadoop)</div><div class="line">2017-09-23 18:01:04,757 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - 2017-09-23 18:01:04,757 Stage-1 map = 100%,  reduce = 100%</div><div class="line">2017-09-23 18:01:04,770 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Ended Job = job_local2008589424_0003</div><div class="line">2017-09-23 18:01:04,776 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - MapReduce Jobs Launched: </div><div class="line">2017-09-23 18:01:04,777 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Stage-Stage-1:  HDFS Read: 264 HDFS Write: 0 SUCCESS</div><div class="line">2017-09-23 18:01:04,777 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Total MapReduce CPU Time Spent: 0 msec</div><div class="line">2017-09-23 18:01:04,777 INFO  [main]: ql.Driver (Driver.java:execute(1696)) - Completed executing <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56); Time taken: 1.43 seconds</div><div class="line">2017-09-23 18:01:04,777 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - OK</div></pre></td></tr></table></figure>
<h5 id="Common-Join-Log說明"><a href="#Common-Join-Log說明" class="headerlink" title="Common Join Log說明:"></a>Common Join Log說明:</h5><ul>
<li>2017-09-23 18:01:04,757 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - 2017-09-23 18:01:04,757 Stage-1 map = 100%,  reduce = 100%<ul>
<li>需要進行Map與Reduce，也就是需要進行Shuffle操作。</li>
</ul>
</li>
</ul>
<h4 id="Map-Join-Log"><a href="#Map-Join-Log" class="headerlink" title="Map Join Log"></a>Map Join Log</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">2017-09-23 18:00:04,948 INFO  [main]: ql.Driver (Driver.java:compile(411)) - Compiling <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56): select a.id, a.name, b.age from a join b on a.id=b.id</div><div class="line">2017-09-23 18:00:05,100 INFO  [main]: ql.Driver (Driver.java:compile(463)) - Semantic Analysis Completed</div><div class="line">2017-09-23 18:00:05,102 INFO  [main]: ql.Driver (Driver.java:getSchema(245)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:a.id, <span class="built_in">type</span>:int, comment:null), FieldSchema(name:a.name, <span class="built_in">type</span>:string, comment:null), FieldSchema(name:b.age, <span class="built_in">type</span>:int, comment:null)], properties:null)</div><div class="line">2017-09-23 18:00:05,112 INFO  [main]: ql.Driver (Driver.java:compile(541)) - Completed compiling <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56); Time taken: 0.164 seconds</div><div class="line">2017-09-23 18:00:05,112 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(165)) - Concurrency mode is disabled, not creating a lock manager</div><div class="line">2017-09-23 18:00:05,112 INFO  [main]: ql.Driver (Driver.java:execute(1448)) - Executing <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56): select a.id, a.name, b.age from a join b on a.id=b.id</div><div class="line">2017-09-23 18:00:05,113 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Query ID = hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56</div><div class="line">2017-09-23 18:00:05,120 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Total <span class="built_in">jobs</span> = 1</div><div class="line">2017-09-23 18:00:05,122 INFO  [main]: ql.Driver (Driver.java:launchTask(1772)) - Starting task [Stage-4:MAPREDLOCAL] <span class="keyword">in</span> serial mode</div><div class="line">2017-09-23 18:00:05,123 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(159)) - Generating plan file file:/tmp/hadoop/6085132e-5e5c-465b-8e67-dd6b58d6518d/hive_2017-09-23_18-00-04_956_7187995778853783363-1/-<span class="built_in">local</span>-10005/plan.xml</div><div class="line">2017-09-23 18:00:05,278 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(288)) - Executing: /opt/software/hadoop/bin/hadoop jar /opt/software/hive-1.1.0-cdh5.7.0/lib/hive-exec-1.1.0-cdh5.7.0.jar org.apache.hadoop.hive.ql.exec.mr.ExecDriver -localtask -plan file:/tmp/hadoop/6085132e-5e5c-465b-8e67-dd6b58d6518d/hive_2017-09-23_18-00-04_956_7187995778853783363-1/-<span class="built_in">local</span>-10005/plan.xml   -jobconffile file:/tmp/hadoop/6085132e-5e5c-465b-8e67-dd6b58d6518d/hive_2017-09-23_18-00-04_956_7187995778853783363-1/-<span class="built_in">local</span>-10006/jobconf.xml</div><div class="line">2017-09-23 18:00:10,522 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Execution completed successfully</div><div class="line">2017-09-23 18:00:10,522 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - MapredLocal task succeeded</div><div class="line">2017-09-23 18:00:10,522 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(313)) - Execution completed successfully</div><div class="line">2017-09-23 18:00:10,523 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Launching Job 1 out of 1</div><div class="line">2017-09-23 18:00:10,526 INFO  [main]: ql.Driver (Driver.java:launchTask(1772)) - Starting task [Stage-3:MAPRED] <span class="keyword">in</span> serial mode</div><div class="line">2017-09-23 18:00:10,526 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Number of reduce tasks is <span class="built_in">set</span> to 0 since theres no reduce operator</div><div class="line">2017-09-23 18:00:10,536 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(286)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</div><div class="line">2017-09-23 18:00:10,537 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(308)) - adding libjars: file:///opt/software/hive/auxlib/com.hive.demo-1.0.jar</div><div class="line">2017-09-23 18:00:10,545 ERROR [main]: mr.ExecDriver (ExecDriver.java:execute(398)) - <span class="built_in">local</span></div><div class="line">2017-09-23 18:00:10,564 WARN  [main]: mapreduce.JobResourceUploader (JobResourceUploader.java:uploadFiles(64)) - Hadoop <span class="built_in">command</span>-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.</div><div class="line">2017-09-23 18:00:10,963 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Job running <span class="keyword">in</span>-process (<span class="built_in">local</span> Hadoop)</div><div class="line">2017-09-23 18:00:11,969 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - 2017-09-23 18:00:11,969 Stage-3 map = 100%,  reduce = 0%</div><div class="line">2017-09-23 18:00:11,977 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Ended Job = job_local1147667645_0002</div><div class="line">2017-09-23 18:00:11,981 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - MapReduce Jobs Launched: </div><div class="line">2017-09-23 18:00:11,981 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Stage-Stage-3:  HDFS Read: 52 HDFS Write: 0 SUCCESS</div><div class="line">2017-09-23 18:00:11,981 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - Total MapReduce CPU Time Spent: 0 msec</div><div class="line">2017-09-23 18:00:11,981 INFO  [main]: ql.Driver (Driver.java:execute(1696)) - Completed executing <span class="built_in">command</span>(queryId=hadoop_20170923175858_4f8377cd-a648-4c9e-8190-b0f7d4326f56); Time taken: 6.869 seconds</div><div class="line">2017-09-23 18:00:11,982 INFO  [main]: ql.Driver (SessionState.java:printInfo(927)) - OK</div></pre></td></tr></table></figure>
<h5 id="Map-Join-Log說明"><a href="#Map-Join-Log說明" class="headerlink" title="Map Join Log說明:"></a>Map Join Log說明:</h5><ul>
<li><p>2017-09-23 18:00:05,122 INFO  [main]: ql.Driver (Driver.java:launchTask(1772)) - Starting task [Stage-4:MAPREDLOCAL] in serial mode</p>
<ul>
<li>此為一個MapReduce Local Task。對應Map Join圖中的MapReduce Local Task方框。</li>
</ul>
</li>
<li><p>2017-09-23 18:00:10,526 INFO  [main]: exec.Task (SessionState.java:printInfo(927)) - Number of reduce tasks is set to 0 since theres no reduce operator</p>
<ul>
<li>此操作沒有Reduce Task</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/18/hive-dml/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/18/hive-dml/" itemprop="url">Hive DML</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-18T12:35:28+08:00">
                2017-09-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hive-Data-Manipulation-Language"><a href="#Hive-Data-Manipulation-Language" class="headerlink" title="Hive Data Manipulation Language"></a>Hive Data Manipulation Language</h2><ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML" title="Hive DML" target="_blank" rel="external">Hive DML 官方文檔</a></li>
</ul>
<h3 id="Loading-files-into-tables"><a href="#Loading-files-into-tables" class="headerlink" title="Loading files into tables"></a>Loading files into tables</h3><p>Syntax<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LOAD DATA [LOCAL] INPATH &apos;filepath&apos; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]</div></pre></td></tr></table></figure></p>
<ul>
<li>LOCAL: 是否從本地文件中載入資料，否則從HDFS中載入。</li>
<li>‘filepath’: 可以為本地文件路徑，或HDFS路徑。</li>
<li>OVERWRITE: 是否重寫資料，否則在尾端追加數據。</li>
</ul>
<h4 id="Loading-file-from-local-file"><a href="#Loading-file-from-local-file" class="headerlink" title="Loading file from local file"></a>Loading file from local file</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 創建一張空表</span></div><div class="line">hive&gt; </div><div class="line">    <span class="keyword">create</span> <span class="keyword">table</span> emp(</div><div class="line">    empno <span class="built_in">int</span>, </div><div class="line">    ename <span class="keyword">string</span>, </div><div class="line">    job <span class="keyword">string</span>, </div><div class="line">    mgr <span class="built_in">int</span>, </div><div class="line">    hiredate <span class="keyword">string</span>, </div><div class="line">    sal <span class="keyword">double</span>, </div><div class="line">    comm <span class="keyword">double</span>, </div><div class="line">    deptno <span class="built_in">int</span></div><div class="line">    )<span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</div><div class="line">OK</div><div class="line">Time taken: 0.838 seconds</div><div class="line"></div><div class="line">hive&gt; show tables;</div><div class="line">OK</div><div class="line">emp</div><div class="line">Time taken: 0.199 seconds, Fetched: 2 row(s)</div><div class="line"></div><div class="line">hive&gt; select * from emp;</div><div class="line">OK</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">-- 從本地文件載入至emp</span></div><div class="line">hive&gt; load data local inpath '/home/hadoop/data/emp.txt' overwrite into table emp;</div><div class="line">Loading data to table default.emp</div><div class="line">Table default.emp stats: [numFiles=1, numRows=0, totalSize=700, rawDataSize=0]</div><div class="line">OK</div><div class="line">Time taken: 2.909 seconds</div><div class="line"></div><div class="line">hive&gt; select * from emp;</div><div class="line">OK</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</div><div class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</div><div class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</div><div class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	NULL	20</div><div class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</div><div class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	NULL	30</div><div class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	NULL	10</div><div class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	NULL	20</div><div class="line">7839	KING	PRESIDENT	NULL	1981-11-17	5000.0	NULL	10</div><div class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</div><div class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	NULL	20</div><div class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	NULL	30</div><div class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	NULL	20</div><div class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	NULL	10</div><div class="line">8888	HIVE	PROGRAM	7839	1988-1-23	10300.0	NULL	NULL</div><div class="line">Time taken: 0.105 seconds, Fetched: 15 row(s)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">-- 從本地文件讀取數據，並追加至emp尾部</span></div><div class="line">hive&gt; load data local inpath '/home/hadoop/data/emp.txt' into table emp;</div><div class="line">Loading data to table default.emp</div><div class="line">Table default.emp stats: [numFiles=2, numRows=0, totalSize=1400, rawDataSize=0]</div><div class="line">OK</div><div class="line">Time taken: 0.673 seconds</div><div class="line"></div><div class="line">hive&gt; select count(*) from emp;</div><div class="line">Query ID = hadoop_20170914005050_bccf96a2-df73-425a-83b5-6e7fe5e6772f</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks determined at compile time: 1</div><div class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-14</span> <span class="number">01</span>:<span class="number">03</span>:<span class="number">29</span>,<span class="number">160</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</div><div class="line">Ended Job = job_local1150048630_0002</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">9800</span> HDFS Write: <span class="number">2800</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">30</span></div></pre></td></tr></table></figure>
<p>在進行資料追加時，顯示下面這行輸出:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Table default.emp stats: [numFiles=2, numRows=0, totalSize=1400, rawDataSize=0]</div></pre></td></tr></table></figure></p>
<p>當中的numFiles表示在對應的hdfs中，包含2個文件。可以使用下列方式進行驗證。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[hadoop@cdh001 ~]$ hadoop fs -ls /user/hive/warehouse/emp</div><div class="line">Found 2 items</div><div class="line">-rwxr-xr-x   1 hadoop supergroup        700 2017-09-14 01:20 /user/hive/warehouse/emp/emp.txt</div><div class="line">-rwxr-xr-x   1 hadoop supergroup        700 2017-09-14 01:21 /user/hive/warehouse/emp/emp_copy_1.txt</div></pre></td></tr></table></figure></p>
<h4 id="Loading-file-from-HDFS"><a href="#Loading-file-from-HDFS" class="headerlink" title="Loading file from HDFS"></a>Loading file from HDFS</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 先將emp清空</span></div><div class="line">hive&gt; truncate table emp;</div><div class="line">OK</div><div class="line">Time taken: 0.222 seconds</div><div class="line"></div><div class="line"><span class="comment">-- 從HDFS上將數據載入</span></div><div class="line"><span class="comment">-- hdfs://cdh001:9000: 對應Hadoop中core-site.xml中的fs.defaultFS配置</span></div><div class="line">hive&gt; load data inpath 'hdfs://cdh001:9000/data/emp.txt' overwrite into table emp;</div><div class="line">Loading data to table default.emp</div><div class="line">Table default.emp stats: [numFiles=1, numRows=0, totalSize=700, rawDataSize=0]</div><div class="line">OK</div><div class="line">Time taken: 0.42 seconds</div><div class="line"></div><div class="line">hive&gt; select count(*) from emp;</div><div class="line">Query ID = hadoop_20170914005050_bccf96a2-df73-425a-83b5-6e7fe5e6772f</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks determined at compile time: 1</div><div class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-14</span> <span class="number">01</span>:<span class="number">16</span>:<span class="number">58</span>,<span class="number">335</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</div><div class="line">Ended Job = job_local978141749_0004</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">11214</span> HDFS Write: <span class="number">2800</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">15</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">1.518</span> seconds, Fetched: <span class="number">1</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
<h4 id="Inserting-data-into-Hive-Tables-from-queries"><a href="#Inserting-data-into-Hive-Tables-from-queries" class="headerlink" title="Inserting data into Hive Tables from queries"></a>Inserting data into Hive Tables from queries</h4><p>Syntax<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) [IF NOT EXISTS]] select_statement1 FROM from_statement;</div><div class="line">INSERT INTO TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 FROM from_statement;</div></pre></td></tr></table></figure></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div></pre></td><td class="code"><pre><div class="line">hive&gt; </div><div class="line">    <span class="keyword">create</span> <span class="keyword">table</span> emp(</div><div class="line">    empno <span class="built_in">int</span>, </div><div class="line">    ename <span class="keyword">string</span>, </div><div class="line">    job <span class="keyword">string</span>, </div><div class="line">    mgr <span class="built_in">int</span>, </div><div class="line">    hiredate <span class="keyword">string</span>, </div><div class="line">    sal <span class="keyword">double</span>, </div><div class="line">    comm <span class="keyword">double</span>, </div><div class="line">    deptno <span class="built_in">int</span></div><div class="line">    )<span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</div><div class="line">OK</div><div class="line">Time taken: 1.36 seconds</div><div class="line"></div><div class="line"><span class="comment">-- 從emp將全部的資料載入，並複寫emp2</span></div><div class="line">hive&gt; insert overwrite table emp2 select * from emp;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 3</div><div class="line">Launching Job 1 out of 3</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since there <span class="keyword">no</span> reduce <span class="keyword">operator</span></div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-14</span> <span class="number">01</span>:<span class="number">45</span>:<span class="number">44</span>,<span class="number">802</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">0</span>%</div><div class="line">Ended Job = job_local2086758437_0002</div><div class="line">Stage<span class="number">-4</span> <span class="keyword">is</span> selected <span class="keyword">by</span> condition resolver.</div><div class="line">Stage<span class="number">-3</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> condition resolver.</div><div class="line">Stage<span class="number">-5</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> condition resolver.</div><div class="line">Moving <span class="keyword">data</span> <span class="keyword">to</span>: hdfs://cdh001:<span class="number">9000</span>/<span class="keyword">user</span>/hive/warehouse/emp2/.hive-staging_hive_2017<span class="number">-09</span><span class="number">-14</span>_01<span class="number">-45</span><span class="number">-43</span>_184_5687343240557641860<span class="number">-1</span>/-ext<span class="number">-10000</span></div><div class="line">Loading <span class="keyword">data</span> <span class="keyword">to</span> <span class="keyword">table</span> default.emp2</div><div class="line"><span class="keyword">Table</span> default.emp2 stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">15</span>, totalSize=<span class="number">708</span>, rawDataSize=<span class="number">693</span>]</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">3586</span> HDFS Write: <span class="number">2963</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="keyword">Time</span> taken: <span class="number">1.999</span> seconds</div><div class="line">hive&gt; <span class="keyword">select</span> * <span class="keyword">from</span> emp2;</div><div class="line">OK</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</div><div class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</div><div class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</div><div class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	NULL	20</div><div class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</div><div class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	NULL	30</div><div class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	NULL	10</div><div class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	NULL	20</div><div class="line">7839	KING	PRESIDENT	NULL	1981-11-17	5000.0	NULL	10</div><div class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</div><div class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	NULL	20</div><div class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	NULL	30</div><div class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	NULL	20</div><div class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	NULL	10</div><div class="line">8888	HIVE	PROGRAM	7839	1988-1-23	10300.0	NULL	NULL</div><div class="line">Time taken: 0.127 seconds, Fetched: 15 row(s)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">-- 從emp將全部的資料載入，並追加至emp2</span></div><div class="line">hive&gt; insert into table emp2 select * from emp;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 3</div><div class="line">Launching Job 1 out of 3</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since theres <span class="keyword">no</span> reduce <span class="keyword">operator</span></div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-14</span> <span class="number">01</span>:<span class="number">50</span>:<span class="number">12</span>,<span class="number">327</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">0</span>%</div><div class="line">Ended Job = job_local1847471355_0004</div><div class="line">Stage<span class="number">-4</span> <span class="keyword">is</span> selected <span class="keyword">by</span> condition resolver.</div><div class="line">Stage<span class="number">-3</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> condition resolver.</div><div class="line">Stage<span class="number">-5</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> condition resolver.</div><div class="line">Moving <span class="keyword">data</span> <span class="keyword">to</span>: hdfs://cdh001:<span class="number">9000</span>/<span class="keyword">user</span>/hive/warehouse/emp2/.hive-staging_hive_2017<span class="number">-09</span><span class="number">-14</span>_01<span class="number">-50</span><span class="number">-10</span>_029_6901561759110802758<span class="number">-1</span>/-ext<span class="number">-10000</span></div><div class="line">Loading <span class="keyword">data</span> <span class="keyword">to</span> <span class="keyword">table</span> default.emp2</div><div class="line"><span class="keyword">Table</span> default.emp2 stats: [numFiles=<span class="number">2</span>, numRows=<span class="number">30</span>, totalSize=<span class="number">1416</span>, rawDataSize=<span class="number">1386</span>]</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">6540</span> HDFS Write: <span class="number">4517</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="keyword">Time</span> taken: <span class="number">2.686</span> seconds</div><div class="line">hive&gt; <span class="keyword">select</span> * <span class="keyword">from</span> emp2;</div><div class="line">OK</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</div><div class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</div><div class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</div><div class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	NULL	20</div><div class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</div><div class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	NULL	30</div><div class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	NULL	10</div><div class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	NULL	20</div><div class="line">7839	KING	PRESIDENT	NULL	1981-11-17	5000.0	NULL	10</div><div class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</div><div class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	NULL	20</div><div class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	NULL	30</div><div class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	NULL	20</div><div class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	NULL	10</div><div class="line">8888	HIVE	PROGRAM	7839	1988-1-23	10300.0	NULL	NULL</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</div><div class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</div><div class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</div><div class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	NULL	20</div><div class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</div><div class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	NULL	30</div><div class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	NULL	10</div><div class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	NULL	20</div><div class="line">7839	KING	PRESIDENT	NULL	1981-11-17	5000.0	NULL	10</div><div class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</div><div class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	NULL	20</div><div class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	NULL	30</div><div class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	NULL	20</div><div class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	NULL	10</div><div class="line">8888	HIVE	PROGRAM	7839	1988-1-23	10300.0	NULL	NULL</div><div class="line">Time taken: 0.086 seconds, Fetched: 30 row(s)</div></pre></td></tr></table></figure>
<h3 id="Writing-data-into-the-filesystem-from-queries"><a href="#Writing-data-into-the-filesystem-from-queries" class="headerlink" title="Writing data into the filesystem from queries"></a>Writing data into the filesystem from queries</h3><p>Syntax<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">INSERT OVERWRITE [LOCAL] DIRECTORY directory1</div><div class="line">  [ROW FORMAT row_format] [STORED AS file_format] (Note: Only available starting with Hive 0.11.0)</div><div class="line">  SELECT ... FROM ...</div></pre></td></tr></table></figure></p>
<h4 id="Writing-data-into-the-local-file"><a href="#Writing-data-into-the-local-file" class="headerlink" title="Writing data into the local file"></a>Writing data into the local file</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">hive&gt; insert overwrite local directory '/home/hadoop/hive_data' </div><div class="line">      row format delimited fields terminated by '\t' <span class="keyword">select</span> * <span class="keyword">from</span> emp;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since there<span class="string">'s no reduce operator</span></div><div class="line"><span class="string">Job running in-process (local Hadoop)</span></div><div class="line"><span class="string">2017-09-15 00:17:19,523 Stage-1 map = 100%,  reduce = 0%</span></div><div class="line"><span class="string">Ended Job = job_local1952623901_0005</span></div><div class="line"><span class="string">Copying data to local directory /home/hadoop/hive_data</span></div><div class="line"><span class="string">MapReduce Jobs Launched: </span></div><div class="line"><span class="string">Stage-Stage-1:  HDFS Read: 8725 HDFS Write: 4517 SUCCESS</span></div><div class="line"><span class="string">Total MapReduce CPU Time Spent: 0 msec</span></div><div class="line"><span class="string">OK</span></div><div class="line"><span class="string">Time taken: 2.298 seconds</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 在對應的本地路徑確認導出的數據，並確認文件內容</span></div><div class="line">[hadoop@cdh001 hive_data]$ ls</div><div class="line">000000_0</div><div class="line">[hadoop@cdh001 hive_data]$ vim 000000_0 </div><div class="line"></div><div class="line">7369    SMITH   CLERK   7902    1980-12-17      800.0   \N      20</div><div class="line">7499    ALLEN   SALESMAN        7698    1981-2-20       1600.0  300.0   30</div><div class="line">7521    WARD    SALESMAN        7698    1981-2-22       1250.0  500.0   30</div><div class="line">7566    JONES   MANAGER 7839    1981-4-2        2975.0  \N      20</div><div class="line">7654    MARTIN  SALESMAN        7698    1981-9-28       1250.0  1400.0  30</div><div class="line">7698    BLAKE   MANAGER 7839    1981-5-1        2850.0  \N      30</div><div class="line">7782    CLARK   MANAGER 7839    1981-6-9        2450.0  \N      10</div><div class="line">7788    SCOTT   ANALYST 7566    1987-4-19       3000.0  \N      20</div><div class="line">7839    KING    PRESIDENT       \N      1981-11-17      5000.0  \N      10</div><div class="line">7844    TURNER  SALESMAN        7698    1981-9-8        1500.0  0.0     30</div><div class="line">7876    ADAMS   CLERK   7788    1987-5-23       1100.0  \N      20</div><div class="line">7900    JAMES   CLERK   7698    1981-12-3       950.0   \N      30</div><div class="line">7902    FORD    ANALYST 7566    1981-12-3       3000.0  \N      20</div><div class="line">7934    MILLER  CLERK   7782    1982-1-23       1300.0  \N      10</div><div class="line">8888    HIVE    PROGRAM 7839    1988-1-23       10300.0 \N      \N</div></pre></td></tr></table></figure>
<h4 id="Writing-data-into-the-HDFS"><a href="#Writing-data-into-the-HDFS" class="headerlink" title="Writing data into the HDFS"></a>Writing data into the HDFS</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">hive&gt; insert overwrite directory 'hdfs://cdh001:9000/hive_data' row format delimited fields terminated by '\t' select * from emp;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 3</div><div class="line">Launching Job 1 out of 3</div><div class="line">Number of reduce tasks is <span class="keyword">set</span> <span class="keyword">to</span> <span class="number">0</span> since theres <span class="keyword">no</span> reduce <span class="keyword">operator</span></div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-15</span> <span class="number">00</span>:<span class="number">27</span>:<span class="number">00</span>,<span class="number">633</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">0</span>%</div><div class="line">Ended Job = job_local1161905320_0006</div><div class="line">Stage<span class="number">-3</span> <span class="keyword">is</span> selected <span class="keyword">by</span> condition resolver.</div><div class="line">Stage<span class="number">-2</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> condition resolver.</div><div class="line">Stage<span class="number">-4</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> condition resolver.</div><div class="line">Moving <span class="keyword">data</span> <span class="keyword">to</span>: hdfs://cdh001:<span class="number">9000</span>/hive_data/.hive-staging_hive_2017<span class="number">-09</span><span class="number">-15</span>_00<span class="number">-26</span><span class="number">-59</span>_185_2874371608777769743<span class="number">-1</span>/-ext<span class="number">-10000</span></div><div class="line">Moving <span class="keyword">data</span> <span class="keyword">to</span>: hdfs://cdh001:<span class="number">9000</span>/hive_data</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">9425</span> HDFS Write: <span class="number">5225</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="keyword">Time</span> taken: <span class="number">1.524</span> seconds</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 在對應的HDFS路徑確認導出的資料，並確認文件內容。</span></div><div class="line">[hadoop@cdh001 hive_data]$ hadoop fs -ls /hive_data</div><div class="line">Found 1 items</div><div class="line">-rwxr-xr-x   1 hadoop supergroup        708 2017-09-15 00:27 /hive_data/000000_0</div><div class="line"></div><div class="line">[hadoop@cdh001 hive_data]$ hadoop fs -cat /hive_data/000000_0</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	\N	20</div><div class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</div><div class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</div><div class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	\N	20</div><div class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</div><div class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	\N	30</div><div class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	\N	10</div><div class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	\N	20</div><div class="line">7839	KING	PRESIDENT	\N	1981-11-17	5000.0	\N	10</div><div class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</div><div class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	\N	20</div><div class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	\N	30</div><div class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	\N	20</div><div class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	\N	10</div><div class="line">8888	HIVE	PROGRAM	7839	1988-1-23	10300.0	\N	\N</div></pre></td></tr></table></figure>
<h3 id="Inserting-values-into-tables-from-SQL"><a href="#Inserting-values-into-tables-from-SQL" class="headerlink" title="Inserting values into tables from SQL"></a>Inserting values into tables from SQL</h3><ul>
<li>大數據場景下不常使用。</li>
<li>Hive 0.14開始支援。</li>
</ul>
<h3 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h3><ul>
<li>大數據場景下不常使用。</li>
<li>Hive 0.14開始支援。</li>
</ul>
<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h3><ul>
<li>大數據場景下不常使用。</li>
<li>Hive 0.14開始支援。</li>
</ul>
<h3 id="Query"><a href="#Query" class="headerlink" title="Query"></a>Query</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 查詢emp中，所有的數據。</span></div><div class="line">hive&gt; select * from emp;</div><div class="line">OK</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</div><div class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</div><div class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</div><div class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	NULL	20</div><div class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</div><div class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	NULL	30</div><div class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	NULL	10</div><div class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	NULL	20</div><div class="line">7839	KING	PRESIDENT	NULL	1981-11-17	5000.0	NULL	10</div><div class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</div><div class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	NULL	20</div><div class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	NULL	30</div><div class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	NULL	20</div><div class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	NULL	10</div><div class="line">8888	HIVE	PROGRAM	7839	1988-1-23	10300.0	NULL	NULL</div><div class="line">Time taken: 0.076 seconds, Fetched: 15 row(s)</div><div class="line"></div><div class="line"><span class="comment">-- 查詢emp中，ename為'SMITH'的紀錄</span></div><div class="line">hive&gt; select * from emp where ename='SMITH';</div><div class="line">OK</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</div><div class="line">Time taken: 0.221 seconds, Fetched: 1 row(s)</div><div class="line"></div><div class="line"><span class="comment">-- 查詢emp table中，sal區間在800~1500的紀錄</span></div><div class="line"><span class="comment">-- where between and 操作，是左右閉合的</span></div><div class="line">hive&gt; select ename, sal from emp where sal between 800 and 1500;</div><div class="line">OK</div><div class="line">SMITH	800.0</div><div class="line">WARD	1250.0</div><div class="line">MARTIN	1250.0</div><div class="line">TURNER	1500.0</div><div class="line">ADAMS	1100.0</div><div class="line">JAMES	950.0</div><div class="line">MILLER	1300.0</div><div class="line">Time taken: 0.081 seconds, Fetched: 7 row(s)</div><div class="line"></div><div class="line"><span class="comment">-- 查詢emp中，deptno是10, 30的數據。</span></div><div class="line">hive&gt; select ename, deptno from emp where deptno in (10,30);</div><div class="line">OK</div><div class="line">ALLEN	30</div><div class="line">WARD	30</div><div class="line">MARTIN	30</div><div class="line">BLAKE	30</div><div class="line">CLARK	10</div><div class="line">KING	10</div><div class="line">TURNER	30</div><div class="line">JAMES	30</div><div class="line">MILLER	10</div><div class="line">Time taken: 0.068 seconds, Fetched: 9 row(s)</div></pre></td></tr></table></figure>
<h3 id="Aggregate-functions"><a href="#Aggregate-functions" class="headerlink" title="Aggregate functions"></a>Aggregate functions</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">hive&gt; select count(1), max(sal), min(sal), avg(sal) from emp;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks determined at compile time: 1</div><div class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-15</span> <span class="number">00</span>:<span class="number">44</span>:<span class="number">49</span>,<span class="number">597</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</div><div class="line">Ended Job = job_local1747076311_0014</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">42650</span> HDFS Write: <span class="number">10450</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="number">15</span>	<span class="number">10300.0</span>	<span class="number">800.0</span>	<span class="number">2621.6666666666665</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">1.344</span> seconds, Fetched: <span class="number">1</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
<h3 id="Group-by"><a href="#Group-by" class="headerlink" title="Group by"></a>Group by</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 查詢每個部門的平均薪水</span></div><div class="line">hive&gt; select deptno, avg(sal) from emp group by deptno;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks not specified. Estimated from input data size: 1</div><div class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">00</span>:<span class="number">17</span>:<span class="number">45</span>,<span class="number">930</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</div><div class="line">Ended Job = job_local1889358448_0027</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">62250</span> HDFS Write: <span class="number">10450</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="literal">NULL</span>	<span class="number">10300.0</span></div><div class="line"><span class="number">10</span>	<span class="number">2916.6666666666665</span></div><div class="line"><span class="number">20</span>	<span class="number">2175.0</span></div><div class="line"><span class="number">30</span>	<span class="number">1566.6666666666667</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">1.328</span> seconds, Fetched: <span class="number">4</span> <span class="keyword">row</span>(s)</div><div class="line"></div><div class="line"><span class="comment">-- 查詢每個工作中在不同部門的最高薪水</span></div><div class="line">hive&gt; <span class="keyword">select</span> job, deptno, <span class="keyword">max</span>(sal) <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> job, deptno;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks not specified. Estimated from input data size: 1</div><div class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">00</span>:<span class="number">15</span>:<span class="number">51</span>,<span class="number">279</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">0</span>%,  reduce = <span class="number">0</span>%</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">00</span>:<span class="number">15</span>:<span class="number">52</span>,<span class="number">281</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</div><div class="line">Ended Job = job_local1502275066_0025</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">59450</span> HDFS Write: <span class="number">10450</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line">ANALYST	<span class="number">20</span>	<span class="number">3000.0</span></div><div class="line">CLERK	<span class="number">10</span>	<span class="number">1300.0</span></div><div class="line">CLERK	<span class="number">20</span>	<span class="number">1100.0</span></div><div class="line">CLERK	<span class="number">30</span>	<span class="number">950.0</span></div><div class="line">MANAGER	<span class="number">10</span>	<span class="number">2450.0</span></div><div class="line">MANAGER	<span class="number">20</span>	<span class="number">2975.0</span></div><div class="line">MANAGER	<span class="number">30</span>	<span class="number">2850.0</span></div><div class="line">PRESIDENT	<span class="number">10</span>	<span class="number">5000.0</span></div><div class="line">PROGRAM	<span class="literal">NULL</span>	<span class="number">10300.0</span></div><div class="line">SALESMAN	<span class="number">30</span>	<span class="number">1600.0</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">3.667</span> seconds, Fetched: <span class="number">10</span> <span class="keyword">row</span>(s)</div><div class="line"></div><div class="line"><span class="comment">-- 查詢各部門1982-01-01之前入職員工的平均薪水</span></div><div class="line">hive&gt; <span class="keyword">select</span> deptno, <span class="keyword">avg</span>(sal) <span class="keyword">from</span> emp <span class="keyword">where</span> hiredate &gt; <span class="keyword">to_date</span>(<span class="string">'1982-01-01'</span>) <span class="keyword">group</span> <span class="keyword">by</span> deptno;</div><div class="line">Query ID = hadoop_20170914014141_a03e8794-0c51-414f-87d7-50236e8e1b36</div><div class="line">Total jobs = 1</div><div class="line">Launching Job 1 out of 1</div><div class="line">Number of reduce tasks not specified. Estimated from input data size: 1</div><div class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</div><div class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</div><div class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</div><div class="line">Job running <span class="keyword">in</span>-process (<span class="keyword">local</span> Hadoop)</div><div class="line"><span class="number">2017</span><span class="number">-09</span><span class="number">-16</span> <span class="number">00</span>:<span class="number">48</span>:<span class="number">00</span>,<span class="number">159</span> Stage<span class="number">-1</span> <span class="keyword">map</span> = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</div><div class="line">Ended Job = job_local1055215937_0030</div><div class="line">MapReduce Jobs Launched: </div><div class="line">Stage-Stage<span class="number">-1</span>:  HDFS <span class="keyword">Read</span>: <span class="number">91650</span> HDFS Write: <span class="number">10450</span> <span class="keyword">SUCCESS</span></div><div class="line">Total MapReduce CPU <span class="keyword">Time</span> Spent: <span class="number">0</span> msec</div><div class="line">OK</div><div class="line"><span class="literal">NULL</span>	<span class="number">10300.0</span></div><div class="line"><span class="number">10</span>	<span class="number">1300.0</span></div><div class="line"><span class="number">20</span>	<span class="number">2050.0</span></div><div class="line"><span class="keyword">Time</span> taken: <span class="number">1.267</span> seconds, Fetched: <span class="number">3</span> <span class="keyword">row</span>(s)</div></pre></td></tr></table></figure>
<ul>
<li>在返回集字段中，這些字段不是包含在group by語句之後，作為分組的依據，否則一定包含在聚合函數中(Aggregate functions)，若不成立，則會報錯，如下:<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hive&gt; select deptno, ename, max(sal) from emp group by deptno; </div><div class="line">FAILED: SemanticException [Error 10025]: Line 1:15 Expression not <span class="keyword">in</span> GROUP BY key <span class="string">'ename'</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Case-when-then"><a href="#Case-when-then" class="headerlink" title="Case when then"></a>Case when then</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">hive&gt; select ename, sal,</div><div class="line">    &gt; case</div><div class="line">    &gt; when sal &gt; 1 and sal &lt;= 1000 then 'LOWER'</div><div class="line">    &gt; when sal &gt; 1000 and sal &lt;= 2000 then 'MIDDLE'</div><div class="line">    &gt; when sal &gt; 2000 and sal &lt;= 4000 then 'HIGH'</div><div class="line">    &gt; else 'HIGJEST' end</div><div class="line">    &gt; from emp;</div><div class="line">OK</div><div class="line">SMITH	800.0	LOWER</div><div class="line">ALLEN	1600.0	MIDDLE</div><div class="line">WARD	1250.0	MIDDLE</div><div class="line">JONES	2975.0	HIGH</div><div class="line">MARTIN	1250.0	MIDDLE</div><div class="line">BLAKE	2850.0	HIGH</div><div class="line">CLARK	2450.0	HIGH</div><div class="line">SCOTT	3000.0	HIGH</div><div class="line">KING	5000.0	HIGJEST</div><div class="line">TURNER	1500.0	MIDDLE</div><div class="line">ADAMS	1100.0	MIDDLE</div><div class="line">JAMES	950.0	LOWER</div><div class="line">FORD	3000.0	HIGH</div><div class="line">MILLER	1300.0	MIDDLE</div><div class="line">HIVE	10300.0	HIGJEST</div><div class="line">Time taken: 0.105 seconds, Fetched: 15 row(s)</div></pre></td></tr></table></figure>
<h3 id="Import-Export"><a href="#Import-Export" class="headerlink" title="Import/Export"></a>Import/Export</h3><ul>
<li>Hive 0.8.0 開始支持。</li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ImportExport&quot;Hive ImportExport&quot;" target="_blank" rel="external">Hive ImportExport 官方文檔</a></li>
</ul>
<h4 id="Export"><a href="#Export" class="headerlink" title="Export"></a>Export</h4><p>Syntax<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">EXPORT TABLE tablename [PARTITION (part_column=&quot;value&quot;[, ...])]</div><div class="line">  TO &apos;export_target_path&apos; [ FOR replication(&apos;eventid&apos;) ]</div></pre></td></tr></table></figure></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hive&gt; export table emp to 'hdfs://cdh001:9000/hive_export_table';</div><div class="line">Copying data from file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_01-23-59_248_7891813049757812255-1/-local-10000/_metadata</div><div class="line">Copying file: file:/tmp/hadoop/2d0fe1f1-954f-4cb7-bc14-1f05d5de3555/hive_2017-09-16_01-23-59_248_7891813049757812255-1/-local-10000/_metadata</div><div class="line">Copying data from hdfs://cdh001:9000/user/hive/warehouse/emp</div><div class="line">Copying file: hdfs://cdh001:9000/user/hive/warehouse/emp/emp.txt</div><div class="line">OK</div><div class="line">Time taken: 0.125 seconds</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[hadoop@cdh001 hive_data]$ hadoop fs -ls /hive_export_table</div><div class="line">Found 2 items</div><div class="line">-rwxr-xr-x   1 hadoop supergroup       1570 2017-09-16 01:23 /hive_export_table/_metadata</div><div class="line">drwxr-xr-x   - hadoop supergroup          0 2017-09-16 01:23 /hive_export_table/data</div></pre></td></tr></table></figure>
<h4 id="Import"><a href="#Import" class="headerlink" title="Import"></a>Import</h4><p>Syntax<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">IMPORT [[EXTERNAL] TABLE new_or_original_tablename [PARTITION (part_column=&quot;value&quot;[, ...])]]</div><div class="line">  FROM &apos;source_path&apos;</div><div class="line">  [LOCATION &apos;import_target_path&apos;]</div></pre></td></tr></table></figure></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">hive&gt; show tables;</div><div class="line">OK</div><div class="line">emp</div><div class="line">emp2</div><div class="line">emp3</div><div class="line">emptest</div><div class="line">hdfsimport</div><div class="line">Time taken: 0.024 seconds, Fetched: 5 row(s)</div><div class="line"></div><div class="line">hive&gt; select * from hdfsimport;</div><div class="line">OK</div><div class="line">7369	SMITH	CLERK	7902	1980-12-17	800.0	NULL	20</div><div class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.0	300.0	30</div><div class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.0	500.0	30</div><div class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.0	NULL	20</div><div class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.0	1400.0	30</div><div class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.0	NULL	30</div><div class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.0	NULL	10</div><div class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.0	NULL	20</div><div class="line">7839	KING	PRESIDENT	NULL	1981-11-17	5000.0	NULL	10</div><div class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.0	0.0	30</div><div class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.0	NULL	20</div><div class="line">7900	JAMES	CLERK	7698	1981-12-3	950.0	NULL	30</div><div class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.0	NULL	20</div><div class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.0	NULL	10</div><div class="line">8888	HIVE	PROGRAM	7839	1988-1-23	10300.0	NULL	NULL</div><div class="line">Time taken: 0.062 seconds, Fetched: 15 row(s)</div></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/13/hive-basic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/13/hive-basic/" itemprop="url">Hive Basics</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-13T12:25:32+08:00">
                2017-09-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hive-Basics"><a href="#Hive-Basics" class="headerlink" title="Hive Basics"></a>Hive Basics</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul>
<li>提供一套SQL語句，稱為Hive QL，作用於分布式存儲系統的文件之上。</li>
<li>為儲存於分布式存儲系統上的結構化數據文件加上schema的概念，映射為一張數據表，便於應用SQL語句進行操作。</li>
<li>將Client提交的SQL語句，解析並轉換成對應的作業。最終通過計算框架完成操作後，將計算結果返回給Client。</li>
<li>提供命令行工具與JDBC驅動，用於連接Client與Hive。</li>
<li>底層支持MapReduce(Hive on MapReduce)、Spark(Hive on Spark)、Tez(Hive on Tez)<ul>
<li>MapReduce雖然性能慢，但是相對於Spark較為穩定，所以大部分生產環境還是跑Hive on MapReduce</li>
</ul>
</li>
<li>支持多種文件壓縮與存儲格式。</li>
</ul>
<h3 id="Why-Hive"><a href="#Why-Hive" class="headerlink" title="Why Hive"></a>Why Hive</h3><ul>
<li>省去撰寫與維護MapReduce程式的繁雜過程。</li>
<li>讓熟悉SQL語法的用戶能快速上手使用HDFS上的數據，並利用SQL語言進行查詢、匯總，以及分析數據。</li>
<li>解決傳統的關聯型數據庫(RMDB)在大數據處理上的瓶頸。</li>
</ul>
<h3 id="Advantages-of-using-Hive"><a href="#Advantages-of-using-Hive" class="headerlink" title="Advantages of using Hive"></a>Advantages of using Hive</h3><ul>
<li>快速開發的能力</li>
<li>擴展能力強</li>
<li>統一的元數據管理<ul>
<li>Metastore<ul>
<li>Database Metadata: location, owner, name</li>
<li>Table Metadata: name, own, location, column, name/type/index, createtime</li>
</ul>
</li>
<li>和Spark/Impala等SQL引擎是通用的</li>
</ul>
</li>
<li>支持udf函數</li>
</ul>
<h3 id="Hive-History"><a href="#Hive-History" class="headerlink" title="Hive History"></a>Hive History</h3><p>下列為Hivez發展歷史中的重要時間點:</p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Version</th>
<th>Stinger version</th>
<th>Feature</th>
</tr>
</thead>
<tbody>
<tr>
<td>2008/8</td>
<td>facebook releases Hive</td>
</tr>
<tr>
<td>2013/05</td>
<td><a href="https://hortonworks.com/blog/apache-hive-0-11-stinger-phase-1-delivered/" title="hive-0.11" target="_blank" rel="external">hive-0.11</a></td>
<td>Stinger Phase 1</td>
<td>ORC/HiveServer2</td>
</tr>
<tr>
<td>2013/10</td>
<td><a href="https://hortonworks.com/blog/announcing-apache-hive-0-12/" title="hive-0.12" target="_blank" rel="external">hive-0.12</a></td>
<td>Stinger Phase 2</td>
<td>ORC improvement</td>
</tr>
<tr>
<td>2013/08</td>
<td><a href="https://hortonworks.com/blog/announcing-apache-hive-0-13-completion-stinger-initiative/" title="hive-0.13" target="_blank" rel="external">hive-0.13</a></td>
<td>Stinger Phase 3</td>
<td>Tez/Vectorized query execution/Cost-based optimizer(CBO)</td>
</tr>
<tr>
<td>2014/09</td>
<td><a href="https://hortonworks.com/blog/stinger-next-enterprise-sql-hadoop-scale-apache-hive/" title="hive-0.13" target="_blank" rel="external">hive-0.13</a></td>
<td>Stinger.next</td>
<td>SQL:2011</td>
</tr>
</tbody>
</table>
<p>Stinger為Hortonwork所開源的專案，目的是為了提高Hive的性能，並支持更多的SQL。</p>
<h3 id="Hive-on-MapReduce-Architecture"><a href="#Hive-on-MapReduce-Architecture" class="headerlink" title="Hive(on MapReduce) Architecture"></a>Hive(on MapReduce) Architecture</h3><img src="/2017/09/13/hive-basic/hive_architecture.svg" width="600">
<ul>
<li>Hive本身不存儲和計算數據，完全依賴於HDFS和MapReduce。</li>
<li>Hive為一個客戶客戶端工具，將SQL語句轉換為相對應的MapReduce作業，然後在Hadoop上進行運算，最終Hadoop直接將結果回覆給Client。</li>
<li>Hive無須部署在所有的集群節點上。</li>
<li>SQL語句解析流程: <ol>
<li>輸入SQL語句</li>
<li>生成抽象語法樹</li>
<li>優化成邏輯執行計畫</li>
<li>優化成物理執行計畫</li>
<li>生成MapReduece作業</li>
</ol>
</li>
<li>Metastore<ul>
<li>儲存Metadata。</li>
<li>Hive預設使用Derby儲存Metadata，但Derby只支持單用戶操作。</li>
<li>可以使用MySQL或Oracle等資料庫替換。</li>
</ul>
</li>
</ul>
<h3 id="Terms"><a href="#Terms" class="headerlink" title="Terms"></a>Terms</h3><ul>
<li>Structure Data:<ul>
<li>能使用二維表描述的資料。</li>
</ul>
</li>
<li>Vectorized Query Execution<ul>
<li>降低常用查詢操作的CPU使用率。</li>
<li>一次對一個Block內的數據同時讀取並處理，一個Block包含1024行數據。</li>
<li>使用相對較少的指令，並在更短的時間內完成操作。</li>
</ul>
</li>
<li>Cost-Based Optimizer(CBO)<ul>
<li>基於所有執行路徑的執行代價，挑選其中代價最小的執行路徑。</li>
<li>使用分而治之策略，先計算路徑上每個節點的執行代價，最後加總後決策。</li>
<li>每個節點的執行代價計算是基於參與計算的數據集的基本訊息，以及節點的計算成本綜合得出。</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/10/mysql-install-from-source/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/10/mysql-install-from-source/" itemprop="url">MySQL install from source</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-10T12:32:35+08:00">
                2017-09-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Install-MySQL-from-sourcecode"><a href="#Install-MySQL-from-sourcecode" class="headerlink" title="Install MySQL from sourcecode"></a>Install MySQL from sourcecode</h2><h3 id="安裝步驟"><a href="#安裝步驟" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="基本訊息"><a href="#基本訊息" class="headerlink" title="基本訊息"></a>基本訊息</h4><ul>
<li>OS: CentOS 6.5 64bit</li>
<li>MySQL: 5.6.23</li>
</ul>
<h4 id="設置MySQL目錄"><a href="#設置MySQL目錄" class="headerlink" title="設置MySQL目錄"></a>設置MySQL目錄</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /usr/local</span></div><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># ls | grep mysql</span></div><div class="line">mysql-5.6.23-linux-glibc2.5-x86_64.tar.gz</div><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># mv mysql-5.6.23-linux-glibc2.5-x86_64 mysql</span></div><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># vi /etc/profile</span></div><div class="line"><span class="comment">## 新增下列兩行在文件中的任一位置，設置MySQL環境變量</span></div><div class="line"><span class="built_in">export</span> MYSQL_HOME=/usr/<span class="built_in">local</span>/mysql</div><div class="line"><span class="built_in">export</span> PATH=<span class="string">"<span class="variable">$MYSQL_HOME</span>/bin:<span class="variable">$PATH</span>"</span></div><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># source /etc/profile</span></div></pre></td></tr></table></figure>
<h4 id="新增Linux的用戶與群組"><a href="#新增Linux的用戶與群組" class="headerlink" title="新增Linux的用戶與群組"></a>新增Linux的用戶與群組</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># groupadd -g 101 dba</span></div><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># useradd -u 514 -g dba -G root -d /usr/local/mysql mysqladmin</span></div><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># id mysqladmin</span></div><div class="line">uid=514(mysqladmin) gid=101(dba) groups=101(dba),0(root)</div></pre></td></tr></table></figure>
<h4 id="建立-etc-my-cnf"><a href="#建立-etc-my-cnf" class="headerlink" title="建立/etc/my.cnf"></a>建立/etc/my.cnf</h4><p>MySQL啟動時，會跟據下列順序，讀取第一個存在的配置文件</p>
<ol>
<li>/etc/my.cnf</li>
<li>/etc/mysql/my.cnf</li>
<li>SYSCONFDIR/my.cnf</li>
<li>$MYSQL_HOME/my.cnf</li>
<li>–defaults-extra-file</li>
<li>~/my.cnf </li>
</ol>
<p>進行/etc/my.cnf配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 <span class="built_in">local</span>]<span class="comment"># vi /etc/my.cnf</span></div><div class="line">[client]</div><div class="line">port            = 3306</div><div class="line">socket          = /usr/<span class="built_in">local</span>/mysql/data/mysql.sock</div><div class="line"> </div><div class="line">[mysqld]</div><div class="line">port            = 3306</div><div class="line">socket          = /usr/<span class="built_in">local</span>/mysql/data/mysql.sock</div><div class="line"></div><div class="line">skip-external-locking</div><div class="line">key_buffer_size = 256M</div><div class="line">sort_buffer_size = 2M</div><div class="line">read_buffer_size = 2M</div><div class="line">read_rnd_buffer_size = 4M</div><div class="line">query_cache_size= 32M</div><div class="line">max_allowed_packet = 16M</div><div class="line">myisam_sort_buffer_size=128M</div><div class="line">tmp_table_size=32M</div><div class="line"></div><div class="line">table_open_cache = 512</div><div class="line">thread_cache_size = 8</div><div class="line">wait_timeout = 86400</div><div class="line">interactive_timeout = 86400</div><div class="line">max_connections = 600</div><div class="line"></div><div class="line"><span class="comment"># Try number of CPU's*2 for thread_concurrency</span></div><div class="line">thread_concurrency = 32</div><div class="line"></div><div class="line"><span class="comment">#isolation level and default engine </span></div><div class="line">default-storage-engine = INNODB</div><div class="line">transaction-isolation = READ-COMMITTED</div><div class="line"></div><div class="line">server-id  = 1</div><div class="line">basedir     = /usr/<span class="built_in">local</span>/mysql</div><div class="line">datadir     = /usr/<span class="built_in">local</span>/mysql/data</div><div class="line">pid-file     = /usr/<span class="built_in">local</span>/mysql/data/hostname.pid</div><div class="line"></div><div class="line"><span class="comment">#open performance schema</span></div><div class="line"><span class="built_in">log</span>-warnings</div><div class="line">sysdate-is-now</div><div class="line"></div><div class="line">binlog_format = MIXED</div><div class="line">log_bin_trust_function_creators=1</div><div class="line"><span class="built_in">log</span>-error  = /usr/<span class="built_in">local</span>/mysql/data/hostname.err</div><div class="line"><span class="built_in">log</span>-bin=/usr/<span class="built_in">local</span>/mysql/arch/mysql-bin</div><div class="line"><span class="comment">#other logs</span></div><div class="line"><span class="comment">#general_log =1</span></div><div class="line"><span class="comment">#general_log_file  = /usr/local/mysql/data/general_log.err</span></div><div class="line"><span class="comment">#slow_query_log=1</span></div><div class="line"><span class="comment">#slow_query_log_file=/usr/local/mysql/data/slow_log.err</span></div><div class="line"></div><div class="line"><span class="comment">#for replication slave</span></div><div class="line"><span class="comment">#log-slave-updates </span></div><div class="line"><span class="comment">#sync_binlog = 1</span></div><div class="line"></div><div class="line"><span class="comment">#for innodb options </span></div><div class="line">innodb_data_home_dir = /usr/<span class="built_in">local</span>/mysql/data/</div><div class="line">innodb_data_file_path = ibdata1:500M:autoextend</div><div class="line">innodb_log_group_home_dir = /usr/<span class="built_in">local</span>/mysql/arch</div><div class="line">innodb_log_files_in_group = 2</div><div class="line">innodb_log_file_size = 200M</div><div class="line"></div><div class="line"><span class="comment">#根據記憶體資源配置</span></div><div class="line">innodb_buffer_pool_size = 2048M</div><div class="line">innodb_additional_mem_pool_size = 50M</div><div class="line">innodb_log_buffer_size = 16M</div><div class="line"></div><div class="line">innodb_lock_wait_timeout = 100</div><div class="line"><span class="comment">#innodb_thread_concurrency = 0</span></div><div class="line">innodb_flush_log_at_trx_commit = 1</div><div class="line">innodb_locks_unsafe_for_binlog=1</div><div class="line"></div><div class="line"><span class="comment">#innodb io features: add for mysql5.5.8</span></div><div class="line">performance_schema</div><div class="line">innodb_read_io_threads=4</div><div class="line">innodb-write-io-threads=4</div><div class="line">innodb-io-capacity=200</div><div class="line"><span class="comment">#purge threads change default(0) to 1 for purge</span></div><div class="line">innodb_purge_threads=1</div><div class="line">innodb_use_native_aio=on</div><div class="line"></div><div class="line"><span class="comment">#case-sensitive file names and separate tablespace</span></div><div class="line">innodb_file_per_table = 1</div><div class="line">lower_case_table_names=1</div><div class="line"></div><div class="line">[mysqldump]</div><div class="line">quick</div><div class="line">max_allowed_packet = 16M</div><div class="line"></div><div class="line">[mysql]</div><div class="line">no-auto-rehash</div><div class="line"></div><div class="line">[mysqlhotcopy]</div><div class="line">interactive-timeout</div><div class="line"></div><div class="line">[myisamchk]</div><div class="line">key_buffer_size = 256M</div><div class="line">sort_buffer_size = 256M</div><div class="line">read_buffer = 2M</div><div class="line">write_buffer = 2M</div></pre></td></tr></table></figure></p>
<h4 id="安裝MySQL"><a href="#安裝MySQL" class="headerlink" title="安裝MySQL"></a>安裝MySQL</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">## 修改相關文件的擁有者與權限</div><div class="line">[root@hadoop-01 local]# chown mysqladmin:dba /etc/my.cnf </div><div class="line">[root@hadoop-01 local]# chmod 640 /etc/my.cnf</div><div class="line">[root@hadoop-01 local]# chown -R mysqladmin:dba /usr/local/mysql</div><div class="line">[root@hadoop-01 local]# chmod -R 755 /usr/local/mysql </div><div class="line">[root@hadoop-01 local]# su - mysqladmin</div><div class="line"></div><div class="line">[mysqladmin@hadoop-01 ~]$ mkdir arch  ## 在/etc/my.cnf所設定的Log存放目錄</div><div class="line">## 進行安裝</div><div class="line">[mysqladmin@hadoop-01 ~]$ scripts/mysql_install_db  --user=mysqladmin --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data</div><div class="line">Installing MySQL system tables..../bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory</div><div class="line"></div><div class="line">## 此錯誤是因為缺少libaio.so包</div><div class="line">[mysqladmin@hadoop-01 ~]$ sudo yum -y install libaio  ## 安裝libaio.so</div><div class="line">## 再次進行安裝</div><div class="line">[mysqladmin@hadoop-01 ~]$ scripts/mysql_install_db  --user=mysqladmin --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data</div><div class="line">Installing MySQL system tables...2017-09-06 00:11:24 0 [Warning] &apos;THREAD_CONCURRENCY&apos; is deprecated and will be removed in a future release.</div><div class="line">2017-09-06 00:11:24 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).</div><div class="line">OK</div><div class="line"></div><div class="line">Filling help tables...2017-09-06 00:11:26 0 [Warning] &apos;THREAD_CONCURRENCY&apos; is deprecated and will be removed in a future release.</div><div class="line">2017-09-06 00:11:26 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).</div><div class="line">OK</div></pre></td></tr></table></figure>
<h4 id="配置開機啟動MySQL"><a href="#配置開機啟動MySQL" class="headerlink" title="配置開機啟動MySQL"></a>配置開機啟動MySQL</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[mysqladmin@hadoop-01 ~]$ su - <span class="comment">## 切換至root</span></div><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /usr/local/mysql</span></div><div class="line">[root@hadoop-01 mysql]<span class="comment"># cp support-files/mysql.server /etc/rc.d/init.d/mysql</span></div><div class="line">[root@hadoop-01 mysql]<span class="comment"># chmod +x /etc/rc.d/init.d/mysql</span></div><div class="line">[root@hadoop-01 mysql]<span class="comment"># chkconfig --del mysql</span></div><div class="line">[root@hadoop-01 mysql]<span class="comment"># chkconfig --add mysql</span></div><div class="line">[root@hadoop-01 mysql]<span class="comment"># chkconfig --level 345 mysql on</span></div></pre></td></tr></table></figure>
<h4 id="啟動MySQL"><a href="#啟動MySQL" class="headerlink" title="啟動MySQL"></a>啟動MySQL</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 mysql]<span class="comment"># su - mysqladmin</span></div><div class="line">[mysqladmin@hadoop-01 ~]$ bin/mysqld_safe &amp;</div><div class="line">[1] 5382</div><div class="line">[mysqladmin@hadoop-01 ~]$ 170906 00:30:44 mysqld_safe Logging to <span class="string">'/usr/local/mysql/data/hostname.err'</span>.</div><div class="line">170906 00:30:44 mysqld_safe Starting mysqld daemon with databases from /usr/<span class="built_in">local</span>/mysql/data</div><div class="line">[mysqladmin@hadoop-01 ~]$ ps -ef|grep mysqld  <span class="comment">## 確認MySQL的行程狀態</span></div><div class="line">514        5382   5358  0 00:30 pts/1    00:00:00 /bin/sh bin/mysqld_safe</div><div class="line">514        6025   5382  1 00:30 pts/1    00:00:00 /usr/<span class="built_in">local</span>/mysql/bin/mysqld --basedir=/usr/<span class="built_in">local</span>/mysql --datadir=/usr/<span class="built_in">local</span>/mysql/data --plugin-dir=/usr/<span class="built_in">local</span>/mysql/lib/plugin --<span class="built_in">log</span>-error=/usr/<span class="built_in">local</span>/mysql/data/hostname.err --pid-file=/usr/<span class="built_in">local</span>/mysql/data/hostname.pid --socket=/usr/<span class="built_in">local</span>/mysql/data/mysql.sock --port=3306</div><div class="line">514        6052   5358  0 00:31 pts/1    00:00:00 grep mysqld</div><div class="line">[mysqladmin@hadoop-01 ~]$ netstat -nlp | grep mysql  <span class="comment">## 確認MySQL的網路狀態</span></div><div class="line">(Not all processes could be identified, non-owned process info</div><div class="line"> will not be shown, you would have to be root to see it all.)</div><div class="line">tcp        0      0 :::3306                     :::*                        LISTEN      6025/mysqld    </div><div class="line">[mysqladmin@hadoop-01 ~]$ service mysql status  <span class="comment">## 確認MySQL的服務運行狀態</span></div><div class="line">MySQL running (6025)                                       [  OK  ]</div></pre></td></tr></table></figure>
<p>若MySQL啟動失敗，可以至$MYSQL_HOME/data/hostname.err下查看日誌。</p>
<h4 id="登入MySQL，進行帳號配置"><a href="#登入MySQL，進行帳號配置" class="headerlink" title="登入MySQL，進行帳號配置"></a>登入MySQL，進行帳號配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line">[mysqladmin@hadoop-01 ~]$ mysql <span class="comment">## 使用空帳號，空密碼登入MySQL</span></div><div class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</div><div class="line">Your MySQL connection id is 1</div><div class="line">Server version: 5.6.23-log MySQL Community Server (GPL)</div><div class="line"></div><div class="line">Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.</div><div class="line"></div><div class="line">Oracle is a registered trademark of Oracle Corporation and/or its</div><div class="line">affiliates. Other names may be trademarks of their respective</div><div class="line">owners.</div><div class="line"></div><div class="line">Type <span class="string">'help;'</span> or <span class="string">'\h'</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">'\c'</span> to clear the current input statement.</div><div class="line"></div><div class="line">mysql&gt;</div><div class="line">mysql&gt; show databases;</div><div class="line">+--------------------+</div><div class="line">| Database           |</div><div class="line">+--------------------+</div><div class="line">| information_schema |</div><div class="line">| mysql              |</div><div class="line">| performance_schema |</div><div class="line">| <span class="built_in">test</span>               |</div><div class="line">+--------------------+</div><div class="line">4 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.01 sec)</div><div class="line"></div><div class="line">mysql&gt; use mysql;   <span class="comment">## MySQL的帳號訊息皆存在此database</span></div><div class="line">Database changed</div><div class="line">mysql&gt; update user <span class="built_in">set</span> password=password(<span class="string">'password'</span>) <span class="built_in">where</span> user=<span class="string">'root'</span>;  <span class="comment">## 設置root帳號的密碼</span></div><div class="line">Query OK, 4 rows affected (0.00 sec)</div><div class="line">Rows matched: 4  Changed: 4  Warnings: 0</div><div class="line"></div><div class="line">mysql&gt; select host, user, password from user;  <span class="comment">## MySQL的帳號訊息皆存在此table</span></div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">| host      | user | password                                  |</div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">| localhost | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| hadoop-01 | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| 127.0.0.1 | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| ::1       | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| localhost |      |                                           |</div><div class="line">| hadoop-01 |      |          |</div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">4 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; delete from user <span class="built_in">where</span> user=<span class="string">''</span>;  <span class="comment">## 刪除空帳號</span></div><div class="line">mysql&gt; select host, user, password from user;</div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">| host      | user | password                                  |</div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">| localhost | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| hadoop-01 | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| 127.0.0.1 | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| ::1       | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">4 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; flush privileges;</div><div class="line">mysql&gt; <span class="built_in">exit</span></div><div class="line">Bye</div></pre></td></tr></table></figure>
<h4 id="使用MySQL-root帳號登入"><a href="#使用MySQL-root帳號登入" class="headerlink" title="使用MySQL root帳號登入"></a>使用MySQL root帳號登入</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div></pre></td><td class="code"><pre><div class="line">[mysqladmin@hadoop-01 ~]$ mysql -uroot -h127.0.0.1 -p3306 -ppassword  <span class="comment">## -p後面直接接密碼，不需空格</span></div><div class="line">Warning: Using a password on the <span class="built_in">command</span> line interface can be insecure.</div><div class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</div><div class="line">Your MySQL connection id is 15</div><div class="line">Server version: 5.6.23-log MySQL Community Server (GPL)</div><div class="line"></div><div class="line">Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.</div><div class="line"></div><div class="line">Oracle is a registered trademark of Oracle Corporation and/or its</div><div class="line">affiliates. Other names may be trademarks of their respective</div><div class="line">owners.</div><div class="line"></div><div class="line">Type <span class="string">'help;'</span> or <span class="string">'\h'</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">'\c'</span> to clear the current input statement.</div><div class="line"></div><div class="line">mysql&gt; show databases; <span class="comment">## 顯示當前用戶有權限訪問的database</span></div><div class="line">+--------------------+</div><div class="line">| Database           |</div><div class="line">+--------------------+</div><div class="line">| information_schema |</div><div class="line">| mysql              |</div><div class="line">| performance_schema |</div><div class="line">| <span class="built_in">test</span>               |</div><div class="line">+--------------------+</div><div class="line">4 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; desc user; <span class="comment">## 顯示table資訊</span></div><div class="line">mysql&gt; show create table user; <span class="comment">## 顯示create database語句</span></div><div class="line"></div><div class="line">mysql&gt; create database dbname DEFAULT CHARACTER SET utf8;  <span class="comment">## 創建database</span></div><div class="line">Query OK, 1 row affected (0.01 sec)</div><div class="line"></div><div class="line">mysql&gt; grant all on dbname.* TO <span class="string">'usera'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'password'</span>; <span class="comment">## 創建user，設置密碼，允許從所有IP登入，並賦予讀存取db下的所有table權限。可對相同使用者重複設置。</span></div><div class="line">Query OK, 0 rows affected (0.04 sec)</div><div class="line"></div><div class="line">mysql&gt; grant all on dbname.* TO <span class="string">'usera'</span>@<span class="string">'192.168.16.130'</span> IDENTIFIED BY <span class="string">'password'</span>;  <span class="comment">## 創建user，設置密碼，允許從指定IP登入，並賦予讀存取db下的所有table權限。</span></div><div class="line">Query OK, 0 rows affected (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; select host, user, password from user;</div><div class="line">+----------------+-------+-------------------------------------------+</div><div class="line">| host           | user  | password                                  |</div><div class="line">+----------------+-------+-------------------------------------------+</div><div class="line">| localhost      | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| hadoop-01      | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| 127.0.0.1      | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| ::1            | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| %              | usera | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| 192.168.16.130 | usera | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">+----------------+-------+-------------------------------------------+</div><div class="line">mysql&gt; flush privileges;</div><div class="line"></div><div class="line">mysql&gt; drop user usera@<span class="string">'%'</span>;  <span class="comment">## 刪除指定用戶與權限</span></div><div class="line">Query OK, 0 rows affected (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; select host, user, password from user;</div><div class="line">+----------------+-------+-------------------------------------------+</div><div class="line">| host           | user  | password                                  |</div><div class="line">+----------------+-------+-------------------------------------------+</div><div class="line">| localhost      | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| hadoop-01      | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| 127.0.0.1      | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| ::1            | root  | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| 192.168.16.130 | usera | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">+----------------+-------+-------------------------------------------+</div><div class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</div><div class="line"></div><div class="line"></div><div class="line">mysql&gt; delete from user <span class="built_in">where</span> user=<span class="string">'usera'</span>;  <span class="comment">## 刪除用戶，但權限會留著</span></div><div class="line">mysql&gt; select host, user, password from user; </div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">| host      | user | password                                  |</div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line">| localhost | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| hadoop-01 | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| 127.0.0.1 | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">| ::1       | root | *2470C0C06DEE42FD1618BB99005ADCA2EC9D1E19 |</div><div class="line">+-----------+------+-------------------------------------------+</div><div class="line"></div><div class="line">mysql&gt; flush privileges;</div><div class="line">Query OK, 0 rows affected (0.00 sec)</div></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/09/spark-compile/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/09/spark-compile/" itemprop="url">Compile Spark source code</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-09T12:22:02+08:00">
                2017-09-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Why-Spark"><a href="#Why-Spark" class="headerlink" title="Why Spark"></a>Why Spark</h3><img src="/2017/09/09/spark-compile/why_spark.svg" width="800">
<h3 id="編譯步驟"><a href="#編譯步驟" class="headerlink" title="編譯步驟"></a>編譯步驟</h3><h3 id="基本訊息"><a href="#基本訊息" class="headerlink" title="基本訊息"></a>基本訊息</h3><ul>
<li>OS: CentOS 6.5 64bit/macOS Sierra</li>
<li>JDK: 8u144</li>
<li>Maven: 3.3.9(Spark source code自帶)</li>
</ul>
<ul>
<li><a href="http://spark.apache.org/downloads.html" title="Spark download" target="_blank" rel="external">Apache Spark下載位置</a></li>
</ul>
<img src="/2017/09/09/spark-compile/spark_compile_1.png" width="800">
<p>如上圖，在Spark頁面選擇Source code進行下載，並進行解壓縮。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 sourcecode]# ls</div><div class="line">spark-2.2.0.tgz  ## 已下載的Spark 2.2.0 source code壓縮包</div><div class="line">[root@hadoop-01 sourcecode]# tar -zxvf spark-2.2.0.tgz</div><div class="line">[root@hadoop-01 sourcecode]# ls</div><div class="line">spark-2.2.0  </div><div class="line">spark-2.2.0.tgz</div><div class="line">[root@hadoop-01 sourcecode]# cd spark-2.2.0</div></pre></td></tr></table></figure>
<ul>
<li><a href="http://spark.apache.org/docs/latest/building-spark.html" title="Building Spark" target="_blank" rel="external">Building Spark官方文檔</a></li>
<li>Spark官方文檔詳細描述如何編譯Spark，下面列出Spark 2.2.0編譯所需步驟與指令。</li>
</ul>
<h4 id="Building-Spark-using-Maven-requires"><a href="#Building-Spark-using-Maven-requires" class="headerlink" title="Building Spark using Maven requires:"></a>Building Spark using Maven requires:</h4><ul>
<li>Maven 3.3.9 or newer</li>
<li>Java 8+, Java 7 was removed as of Spark 2.2.0.</li>
<li>Set JAVA_HOME<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 spark-2.2.0]<span class="comment"># cd build/  ## Spark source code目錄內自帶的Maven</span></div><div class="line">[root@hadoop-01 build]<span class="comment"># mvn -version     ## 確認Maven與Java版本，分別為Maven 3.3.9與Java 1.8.0_144</span></div><div class="line">Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)</div><div class="line">Maven home: /opt/software/apache-maven-3.3.9</div><div class="line">Java version: 1.8.0_144, vendor: Oracle Corporation</div><div class="line">Java home: /usr/java/jdk1.8.0_144/jre</div><div class="line">Default locale: en_US, platform encoding: UTF-8</div><div class="line">OS name: <span class="string">"linux"</span>, version: <span class="string">"2.6.32-431.el6.x86_64"</span>, arch: <span class="string">"amd64"</span>, family: <span class="string">"unix"</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Setting-up-Maven’s-Memory-Usage"><a href="#Setting-up-Maven’s-Memory-Usage" class="headerlink" title="Setting up Maven’s Memory Usage"></a>Setting up Maven’s Memory Usage</h4><ul>
<li>使用MAVEN_OPTS參數設置Maven可使用的記憶體上限。<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 spark-2.2.0]<span class="comment"># export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="build-mvn"><a href="#build-mvn" class="headerlink" title="build/mvn"></a>build/mvn</h4><ul>
<li>使用Spark source code內在build目錄下自帶Maven進行編譯</li>
<li>此命令會自動下載編譯所需的資源(Maven, Scala, and Zinc)在build目錄下並安裝</li>
<li>下列指令使用預設值編譯Spark<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 spark-2.2.0]<span class="comment"># ./build/mvn -DskipTests clean package</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Building-a-Runnable-Distribution"><a href="#Building-a-Runnable-Distribution" class="headerlink" title="Building a Runnable Distribution"></a>Building a Runnable Distribution</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 spark-2.2.0]<span class="comment"># vim pom.xml ## 首先觀察pom.xml中，需要關注的內容</span></div><div class="line">&lt;properties&gt;</div><div class="line">    &lt;hadoop.version&gt;2.6.5&lt;/hadoop.version&gt;</div><div class="line">    &lt;protobuf.version&gt;2.5.0&lt;/protobuf.version&gt;</div><div class="line">    &lt;yarn.version&gt;<span class="variable">$&#123;hadoop.version&#125;</span>&lt;/yarn.version&gt;</div><div class="line">&lt;/properties&gt;</div><div class="line"></div><div class="line"> &lt;!-- A series of build profiles <span class="built_in">where</span> customizations <span class="keyword">for</span> particular Hadoop releases can be made --&gt;</div><div class="line">&lt;profiles&gt;</div><div class="line">    &lt;profile&gt;</div><div class="line">        &lt;id&gt;hadoop-2.6&lt;/id&gt;</div><div class="line">        &lt;!-- Default hadoop profile. Uses global properties. --&gt;</div><div class="line">    &lt;/profile&gt;</div><div class="line"></div><div class="line">    &lt;profile&gt;</div><div class="line">        &lt;id&gt;hadoop-2.7&lt;/id&gt;</div><div class="line">        &lt;properties&gt;</div><div class="line">        &lt;hadoop.version&gt;2.7.3&lt;/hadoop.version&gt;</div><div class="line">        &lt;/properties&gt;</div><div class="line">    &lt;/profile&gt;</div><div class="line"></div><div class="line">    &lt;profile&gt;</div><div class="line">      &lt;id&gt;yarn&lt;/id&gt;</div><div class="line">      &lt;modules&gt;</div><div class="line">        &lt;module&gt;resource-managers/yarn&lt;/module&gt;</div><div class="line">        &lt;module&gt;common/network-yarn&lt;/module&gt;</div><div class="line">      &lt;/modules&gt;</div><div class="line">    &lt;/profile&gt;  </div><div class="line"></div><div class="line">    &lt;profile&gt;</div><div class="line">      &lt;id&gt;hive-thriftserver&lt;/id&gt;</div><div class="line">      &lt;modules&gt;</div><div class="line">        &lt;module&gt;sql/hive-thriftserver&lt;/module&gt;</div><div class="line">      &lt;/modules&gt;</div><div class="line">    &lt;/profile&gt;      </div><div class="line">&lt;/profiles&gt;</div></pre></td></tr></table></figure>
<ul>
<li>由pom.xml得知訊息<ul>
<li>properties section:<ul>
<li>編譯預設支援hadoop2.6.5</li>
<li>編譯預設支援yarn的版本與hadoop相同</li>
</ul>
</li>
<li>profiles section:<ul>
<li>可支援的hadoop為2.6與2.7，預設為2.6</li>
</ul>
</li>
</ul>
</li>
<li>目標平台使用Hadoop版本為2.8.1，使用下述命令進行編譯<ul>
<li>./dev/make-distribution.sh –name spark-2.2.0 –tgz  -Pyarn -Phadoop-2.8 -Phive -Phive-thriftserver -Dhadoop.version=2.8.1</li>
</ul>
</li>
<li>參數說明:<ul>
<li>–name: 輸出名稱，make-distribution.sh內指出此參數將會替代spark-$VERSION-bin-$NAME中的$NAME</li>
<li>–tgz: 輸出tgz包</li>
<li>-Pyarn: 支援yarn, 指定profile中對應的id</li>
<li>-Phadoop-2.7: 由<a href="http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn" title="Specifying hadoop version" target="_blank" rel="external">Spark官方文檔</a>得知，若要支援Hadoop 2.7+的版本，此參數指定為-Phadoop-2.7</li>
<li>-Phive: 支援hive</li>
<li>-Phive-thriftserver: 支援hive-thriftserver，指定profile中對應的id</li>
<li>-Dhadoop.version=2.8.1: 指定property中Hadoop版本為2.8.1，替換掉pom.xml內的2.6.5</li>
</ul>
</li>
<li>make-distribution.sh內最終會執行/build/mvn，並自動設置MAVEN_OPTS，以及在編譯命令中加上 -DskipTests clean package</li>
<li>在編譯命令中加上-X，可以得到詳細的輸出訊息，可用於錯誤原因確認<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 spark-2.2.0]<span class="comment"># ./dev/make-distribution.sh --name spark-2.2.0 --tgz  -Pyarn -Phadoop-2.8 -Phive -Phive-thriftserver -Dhadoop.version=2.8.1</span></div><div class="line">main:</div><div class="line">[INFO] Executed tasks</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] Reactor Summary:</div><div class="line">[INFO] </div><div class="line">[INFO] Spark Project Parent POM ........................... SUCCESS [  7.014 s]</div><div class="line">[INFO] Spark Project Tags ................................. SUCCESS [  7.707 s]</div><div class="line">[INFO] Spark Project Sketch ............................... SUCCESS [  6.783 s]</div><div class="line">[INFO] Spark Project Networking ........................... SUCCESS [ 20.351 s]</div><div class="line">[INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [ 15.513 s]</div><div class="line">[INFO] Spark Project Unsafe ............................... SUCCESS [ 15.655 s]</div><div class="line">[INFO] Spark Project Launcher ............................. SUCCESS [ 19.657 s]</div><div class="line">[INFO] Spark Project Core ................................. SUCCESS [03:15 min]</div><div class="line">[INFO] Spark Project ML Local Library ..................... SUCCESS [ 15.572 s]</div><div class="line">[INFO] Spark Project GraphX ............................... SUCCESS [ 27.722 s]</div><div class="line">[INFO] Spark Project Streaming ............................ SUCCESS [01:01 min]</div><div class="line">[INFO] Spark Project Catalyst ............................. SUCCESS [01:50 min]</div><div class="line">[INFO] Spark Project SQL .................................. SUCCESS [02:45 min]</div><div class="line">[INFO] Spark Project ML Library ........................... SUCCESS [01:51 min]</div><div class="line">[INFO] Spark Project Tools ................................ SUCCESS [  2.650 s]</div><div class="line">[INFO] Spark Project Hive ................................. SUCCESS [ 59.211 s]</div><div class="line">[INFO] Spark Project REPL ................................. SUCCESS [  8.718 s]</div><div class="line">[INFO] Spark Project YARN Shuffle Service ................. SUCCESS [ 18.745 s]</div><div class="line">[INFO] Spark Project YARN ................................. SUCCESS [ 18.137 s]</div><div class="line">[INFO] Spark Project Hive Thrift Server ................... SUCCESS [ 38.423 s]</div><div class="line">[INFO] Spark Project Assembly ............................. SUCCESS [  4.710 s]</div><div class="line">[INFO] Spark Project External Flume Sink .................. SUCCESS [ 16.745 s]</div><div class="line">[INFO] Spark Project External Flume ....................... SUCCESS [ 17.172 s]</div><div class="line">[INFO] Spark Project External Flume Assembly .............. SUCCESS [  4.797 s]</div><div class="line">[INFO] Spark Integration <span class="keyword">for</span> Kafka 0.8 .................... SUCCESS [ 15.995 s]</div><div class="line">[INFO] Kafka 0.10 Source <span class="keyword">for</span> Structured Streaming ......... SUCCESS [ 13.452 s]</div><div class="line">[INFO] Spark Project Examples ............................. SUCCESS [ 30.937 s]</div><div class="line">[INFO] Spark Project External Kafka Assembly .............. SUCCESS [  6.090 s]</div><div class="line">[INFO] Spark Integration <span class="keyword">for</span> Kafka 0.10 ................... SUCCESS [ 14.209 s]</div><div class="line">[INFO] Spark Integration <span class="keyword">for</span> Kafka 0.10 Assembly .......... SUCCESS [  5.213 s]</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] BUILD SUCCESS</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] Total time: 17:37 min</div><div class="line">[INFO] Finished at: 2017-09-02T00:22:22+08:00</div><div class="line">[INFO] Final Memory: 83M/352M</div><div class="line"></div><div class="line"></div><div class="line">+ TARDIR_NAME=spark-2.2.0-bin-custom-spark</div><div class="line">+ TARDIR=/opt/sourcecode/spark-2.2.0/spark-2.2.0-bin-custom-spark</div><div class="line"></div><div class="line"><span class="comment">## 由TARDIR_NAME與TARDIR變量可得知編譯輸出tgz包的名稱與位置</span></div><div class="line">[root@hadoop-01 spark-2.2.0]<span class="comment"># ll | grep spark-2.2.0-bin-custom-spark</span></div><div class="line">-rw-r--r--.  1 root      root      194582530 Sep  2 00:22 spark-2.2.0-bin-custom-spark.tgz</div></pre></td></tr></table></figure>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/30/yarn-basics/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/30/yarn-basics/" itemprop="url">YARN Basics</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-30T11:41:58+08:00">
                2017-08-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" title="YARN" target="_blank" rel="external">Apache Hadoop YARN官網</a></li>
<li>分布式資源調度框架，用以提高分布式集群環境下的資源利用率。</li>
<li>將資源管理功能(ResourceManager)與作業調度和監控(ApplicationMaster)分別使用不同的Daemon進行。</li>
<li>集群資源統一管理，支援大部份大數據處理框架，例如MapReduce、Spark、Storm等，降低運維成本。</li>
</ul>
<h3 id="Core-components"><a href="#Core-components" class="headerlink" title="Core components"></a>Core components</h3><ul>
<li>Client<ul>
<li>提交啟動/結束一個應用程式/作業。</li>
</ul>
</li>
<li>ResourceManager<ul>
<li>全局主節點。</li>
<li>可以做到主備，但Active的只有一個，另一個做備援。</li>
<li>負責整個集群的資源管理和調度。</li>
<li>處理Client請求(啟動/殺死一個作業)。</li>
</ul>
</li>
<li>NodeManager<ul>
<li>每個節點上的資源管理和Task的運行情況。</li>
<li>接收來自ApplicationMaster的Container的啟動/停止的各種命令。</li>
<li>定期透過Heartbeat向ResourceManager匯報當前節點的資源情況。</li>
</ul>
</li>
<li>ApplicationMaster<ul>
<li>每個應用程式/作業對應一個ApplicationMaster。</li>
<li>負責應用程式/作業的管理。</li>
<li>數據切分。</li>
<li>為應用程式/作業向ResourceManager申請資源(Container)，並分配給Task。</li>
<li>與NodeManager溝通以啟動/停止Container。</li>
<li>Task的監控與容錯。</li>
</ul>
</li>
<li>Container<ul>
<li>動態資源分配單元。</li>
<li>對Task的運行狀況的資源量進行描述，包含cpu、memory、硬碟空間、網路等。</li>
</ul>
</li>
</ul>
<h3 id="Application-submission-in-YARN"><a href="#Application-submission-in-YARN" class="headerlink" title="Application submission in YARN"></a>Application submission in YARN</h3><p><img src="/2017/08/30/yarn-basics/YARN_Process.svg" width="800"></p>
<ol>
<li>Client向ResourceManager提交應用程式，其中包含ApplicationMaster程式、啟動ApplicationMaster的命令、應用程式等。</li>
<li>ResourceManager為該應用程式分配一個Container。</li>
<li><ul>
<li>ResourceManager與對應的NodeManager溝通，要求NodeManager在這個Container啟動應用程式的ApplicationMaster。</li>
<li>若運行過程中，ApplicationMaster異常終止了，NodeManager將通知ResourceManager。ResourceManager將會重啟一個Container執行ApplicationMaster。</li>
</ul>
</li>
<li><ul>
<li>ApplicationMaster向ResourceManager註冊自己，並且與ResourceManager保持Heartbeat。</li>
<li>ApplicationMaster採用輪詢的方式透過RPC協議向ResourceManager申請和領取Container。，並監控Task的運行狀態，直到運行結束。</li>
</ul>
</li>
<li><ul>
<li>Container申請成功後，由ApplicationMaster進行初始化，然後ApplicationMaster與對應的NodeManager溝通，要求NodeManager啟動Container。</li>
<li>ApplicationMaster與NodeManager保持Heartbeat，用以對Task進行監控與管理。</li>
</ul>
</li>
<li><ul>
<li>NodeManager啟動對應的Container。</li>
<li>Container透過RPC協議向對應的ApplicationMaster匯報任務狀態與進度，讓ApplicationMaster掌握各個Task的運行狀態，並在Task失敗時重新啟動之。</li>
<li>應用程式運行結束後，ApplicationMaster向ResourceManager註銷自己，並允許屬於它的Container被回收。</li>
</ul>
</li>
</ol>
<h4 id="Run-a-application-on-YARN"><a href="#Run-a-application-on-YARN" class="headerlink" title="Run a application on YARN"></a>Run a application on YARN</h4><p>下面說明提交一個應用程序/作業到YARN上面執行。</p>
<pre><code class="bash">[hadoop@hadoop-01 ~]$cp /opt/software/hadoop/sbin  ## 進入Hadoop的sbin目錄
[hadoop@hadoop-01 sbin]$ ./start-yarn.sh  ## 執行YARN
starting yarn daemons
starting resourcemanager, logging to /opt/software/hadoop-2.8.1/logs/yarn-hadoop-resourcemanager-hadoop-01.out
hadoop-01: starting nodemanager, logging to /opt/software/hadoop-2.8.1/logs/yarn-hadoop-nodemanager-hadoop-01.out
[hadoop@hadoop-01 sbin]$ ./start-dfs.sh  ## 執行HDFS
Starting namenodes on [localhost]
localhost: starting namenode, logging to /opt/software/hadoop-2.8.1/logs/hadoop-hadoop-namenode-hadoop-01.out
hadoop-01: starting datanode, logging to /opt/software/hadoop-2.8.1/logs/hadoop-hadoop-datanode-hadoop-01.out
Starting secondary namenodes [hadoop-01]
hadoop-01: starting secondarynamenode, logging to /opt/software/hadoop-2.8.1/logs/hadoop-hadoop-secondarynamenode-hadoop-01.out
[hadoop@hadoop-01 sbin]$ jps  ## 透過jps命令，確認YARN與HDFS相關行程正常啟動
21888 NameNode
22001 DataNode
21105 NodeManager
22212 SecondaryNameNode
20996 ResourceManager
22325 Jps
</code></pre>
<img src="/2017/08/30/yarn-basics/yarn_process_1.png" width="1000">
<p>透過Web頁面，確認YARN已正常運行中，並等待應用程式/作業上傳。<br><br></p>
<pre><code class="bash">[hadoop@hadoop-01 sbin]$ cd ../bin  ## 進入Hadoop bin目錄
[hadoop@hadoop-01 bin]$ hadoop
Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]
  jar &lt;jar&gt;            run a jar file
                       note: please use &quot;yarn jar&quot; to launch
                             YARN applications, not this command.
## 透過hadoop jar &lt;jar&gt; 命令，上傳一個mapreduce應用程式
## hadoop-mapreduce-examples-2.8.1.jar為Hadoop自帶的示例
[hadoop@hadoop-01 bin]$ hadoop jar ../share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar pi 10 10
17/08/30 01:32:51 INFO mapreduce.JobSubmitter: number of splits:10
17/08/30 01:32:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1504026603603_0001
17/08/30 01:32:52 INFO impl.YarnClientImpl: Submitted application application_1504026603603_0001
17/08/30 01:32:52 INFO mapreduce.Job: The url to track the job: http://hadoop-01:8088/proxy/application_1504026603603_0001/
17/08/30 01:32:52 INFO mapreduce.Job: Running job: job_1504026603603_0001
17/08/30 01:33:06 INFO mapreduce.Job: Job job_1504026603603_0001 running in uber mode : false
17/08/30 01:33:06 INFO mapreduce.Job:  map 0% reduce 0%
17/08/30 01:33:49 INFO mapreduce.Job:  map 60% reduce 0%
17/08/30 01:34:10 INFO mapreduce.Job:  map 80% reduce 0%
17/08/30 01:34:11 INFO mapreduce.Job:  map 90% reduce 0%
17/08/30 01:34:12 INFO mapreduce.Job:  map 100% reduce 0%
17/08/30 01:34:13 INFO mapreduce.Job:  map 100% reduce 100%
17/08/30 01:34:13 INFO mapreduce.Job: Job job_1504026603603_0001 completed successfully
17/08/30 01:34:13 INFO mapreduce.Job: Counters: 49
    File System Counters
        FILE: Number of bytes read=226
        FILE: Number of bytes written=1503073
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=2650
        HDFS: Number of bytes written=215
        HDFS: Number of read operations=43
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=3
    Job Counters 
        Launched map tasks=10
        Launched reduce tasks=1
        Data-local map tasks=10
        Total time spent by all maps in occupied slots (ms)=324597
        Total time spent by all reduces in occupied slots (ms)=21100
        Total time spent by all map tasks (ms)=324597
        Total time spent by all reduce tasks (ms)=21100
        Total vcore-milliseconds taken by all map tasks=324597
        Total vcore-milliseconds taken by all reduce tasks=21100
        Total megabyte-milliseconds taken by all map tasks=332387328
        Total megabyte-milliseconds taken by all reduce tasks=21606400
    Map-Reduce Framework
        Map input records=10
        Map output records=20
        Map output bytes=180
        Map output materialized bytes=280
        Input split bytes=1470
        Combine input records=0
        Combine output records=0
        Reduce input groups=2
        Reduce shuffle bytes=280
        Reduce input records=20
        Reduce output records=0
        Spilled Records=40
        Shuffled Maps =10
        Failed Shuffles=0
        Merged Map outputs=10
        GC time elapsed (ms)=5918
        CPU time spent (ms)=12010
        Physical memory (bytes) snapshot=2271346688
        Virtual memory (bytes) snapshot=22685822976
        Total committed heap usage (bytes)=1648820224
    Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
    File Input Format Counters 
        Bytes Read=1180
    File Output Format Counters 
        Bytes Written=97
Job Finished in 83.85 seconds
Estimated value of Pi is 3.20000000000000000000
</code></pre>
<img src="/2017/08/30/yarn-basics/yarn_process_2.png" width="1000">
<p>剛開始執行作業時的Web頁面，對應的Status欄位會顯示Running<br><br><br><img src="/2017/08/30/yarn-basics/yarn_process_2.png" width="1000"><br>作業執行完畢時的Web頁面，對應的Status欄位會顯示FINISHED，FinalStatus會顯示SUCCEEDED。生產環境上，則會顯示對應的作業運行狀態。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/28/hdfs-read-write-procedure/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/28/hdfs-read-write-procedure/" itemprop="url">HDFS文件讀寫流程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-28T12:20:51+08:00">
                2017-08-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="HDFS文件讀寫流程"><a href="#HDFS文件讀寫流程" class="headerlink" title="HDFS文件讀寫流程"></a>HDFS文件讀寫流程</h2><h3 id="文件寫入流程"><a href="#文件寫入流程" class="headerlink" title="文件寫入流程"></a>文件寫入流程</h3><img src="/2017/08/28/hdfs-read-write-procedure/HDFS_file_write_procedure.svg" width="800">
<ol>
<li>HDFS Client調用DistributedFileSystem的create()創建一个文件，DistributedFileSystem內部通過RPC呼叫NameNode。</li>
<li>NameNode對請求文件進行檢查:<br> 2.1 文件是否存在<br> 2.2 檢查Client權限是否合法</li>
<li>通過檢查後，NameNode會創建不包含任何Block訊息的新文件，進行紀錄佔位。</li>
<li>詳細描述如下:<br> 4.1 DistributedFileSystem會返回FSDataOutputStream，供客戶端寫入數據。<br> 4.2 FSDataOutputStream包裝了FSOutputStream，可對NameNode與DataNodes進行溝通。<br> 4.3 DFSOutputStream將文件分割成許多的小數據包，並寫入DataQueue。DataQueue由DataStreamer負責讀取。<br> 4.4 DataStreamer通知NameNode分配DataNode儲存Block及副本。</li>
<li>根據副本放置策略，NameNode進行DataNode分配，並返回DataNode列表</li>
<li>詳細描述如下:<br> 6.1 DataStreamer將分配好的DataNode會組成一個Pipeline。假設副本係數為3，所以在Pipeline中會有3個DataNode。<br> 6.2 DataStreamer將Block流式傳送到Pipeline中的第一個DataNode，第一個DataNode將數據往下傳遞給第二個DataNode，第二個DataNode再傳給第三個DataNode</li>
<li>DFSOutputStream維護ackqueue，ackqueue儲存等待DataNode確認的Block，只有當Pipeline內所有的DataNode皆返回寫入成功時，才會從ackqueue刪除，並開始寫入下一個Block。</li>
<li>當目標文件所有的Block寫入完畢，Client通知NameNode寫入操作完畢。</li>
</ol>
<h3 id="文件存取流程"><a href="#文件存取流程" class="headerlink" title="文件存取流程"></a>文件存取流程</h3><img src="/2017/08/28/hdfs-read-write-procedure/HDFS_file_read_procedure.svg" width="800">
<ol>
<li>HDFS Client調用FileSystem對象的靜態方法open()，打開一個目標文件的路徑。FileSystem對象(DistributedFileSystem對象)內部通過RPC呼叫NameNode。</li>
<li>NameNode返回Block列表，該列表視檔案大小情況，包含目標文件部分或全部的Block訊息，對於每個Block，NameNode返回該Block副本的DataNode位址，且DataNode地址會根據與Client的距離來排序。</li>
<li>詳細描述如下:<br> 3.1 DistributedFileSystem返回一个FSDataInputStream對象供Client讀取數據。<br> 3.2 FSDataOutputStream包裝了FSOutputStream，可對NameNode與DataNodes進行溝通。<br> 3.3 使用FSDataInputStream的輸入流調用read()，輸入流會跟據Client與DataNode的距離，挑選DataNode來讀取Block，若Client本身就是DataNode，則從本地獲取數據。<br> 3.4 讀取完當前Block後，關閉與當前DataNode的連結，並讀取Block列表中下個Block訊息與尋找最佳DataNode。<br> 3.5 若Block列表讀取完畢，但文件讀取還沒結束，則Client需再次向NameNode獲取下一批Block列表。直到目標文件所有的Blocks讀取完畢。<br> 3.6 每當讀取完一個Block都會進行checksum校驗，若讀取DataNode時出現錯誤，則Client會通知NameNode，避免下一次錯誤再次發生。而Client則從下一個Block副本的DataNode中讀取數據。</li>
<li>調用FSDataInputStream的close()，通知NameNode讀取操作完畢。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/27/hdfs-basics/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/27/hdfs-basics/" itemprop="url">HDFS Basics</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-27T00:15:01+08:00">
                2017-08-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="HDFS-Hadoop-Distributed-File-System"><a href="#HDFS-Hadoop-Distributed-File-System" class="headerlink" title="HDFS(Hadoop Distributed File System)"></a>HDFS(Hadoop Distributed File System)</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" title="HDFS" target="_blank" rel="external">Apache HDFS官網</a></li>
<li>可運行在普通且廉價的硬體上</li>
<li>高容錯能力</li>
<li>提供應用程式對數據的高吞吐量(high throughput)訪問，適用於具有大數據集的應用程式</li>
</ul>
<h3 id="Assumptions-and-Goals"><a href="#Assumptions-and-Goals" class="headerlink" title="Assumptions and Goals"></a>Assumptions and Goals</h3><ul>
<li>Hardware Failure<ul>
<li>快速硬體錯誤偵測與自動復原機制</li>
</ul>
</li>
<li>Streaming Data Access<ul>
<li>供數據批次處理的應用程式使用，並追求數據訪問的高吞吐量</li>
</ul>
</li>
<li>Large Data Sets<ul>
<li>支持大文件存儲，並支持高聚合數據带寬及高擴展性</li>
</ul>
</li>
<li>Simple Coherency Model<ul>
<li>支持write-once-read-many access的文件存取模型</li>
</ul>
</li>
<li>Moving Computation is Cheaper than Moving Data<ul>
<li>將應用程式的計算移動到數據所在節點附近進行運算，降低網路阻塞，並提高數據吞吐量</li>
</ul>
</li>
<li>Portability Across Heterogeneous Hardware and Software Platforms<ul>
<li>支持平台間的可移植性</li>
</ul>
</li>
</ul>
<h3 id="Core-components"><a href="#Core-components" class="headerlink" title="Core components"></a>Core components</h3><p>HDFS是一個主從式架構(master/slave)，一個HDFS集群(cluster)內，包含一個NameNode與多個DataNode。HDFS提供文件系統命名空間(File System Namespace)給使用者，讓使用者將數據儲存在文件中。下列分別說明NameNode與DataNodes。</p>
<ul>
<li><p>NameNode</p>
<ul>
<li>Master(單個)</li>
<li>管理File System Namespace，例如文件開啟、關閉、重新命名文件或資料夾</li>
<li>決定Block儲存的DataNode</li>
<li>負責響應客戶端的請求，以及文件存取權限控制</li>
<li>負責管理以下數據:<ul>
<li>元數據(Metadata)管理:<ul>
<li>文件名稱</li>
<li>文件屬性(權限、創建時間、副本係數)</li>
</ul>
</li>
<li>文件目錄結構</li>
<li>文件對應的Block，以及Block所存放的DataNode</li>
</ul>
</li>
</ul>
</li>
<li><p>DataNodes</p>
<ul>
<li>Slaves(一個以上)</li>
<li>一般是一個節點執行一個DataNode</li>
<li>存放Block</li>
<li>執行Block的創建、刪除與副本操作</li>
<li>每隔3秒向NameNode發送Heartbeat<ul>
<li>Heartbeat表示該DataNode運作正常</li>
</ul>
</li>
<li>每隔10個Heartbeat(30秒)，向NameNode發送BlockReport<ul>
<li>BlockReport包含該DataNode上所有的Block列表</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>其他說明:<ul>
<li>NameNode與DataNodes皆可運行在普通的機器上。</li>
<li>NameNode與DataNodes皆使用JAVA實作，故任何支援JAVA運行的機器皆可執行。</li>
<li>NameNode與DataNodes一般是運行在不同的機器上。</li>
</ul>
</li>
</ul>
<h3 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h3><ul>
<li>在HDFS中，文件會根據hdfs-default.xml或hdfs-site.xml中的dfs.blocksize參數進行切割成Blocks。</li>
<li>dfs.blocksize預設為128M，當檔案大於128M時，則會進行切割，直到最後一個Block等於或小於128M。</li>
<li>寫入時，文件會拆分成多個Block儲存在不同的DataNode。</li>
<li>讀取時，則從DataNodes中取出Blocks進行合併。</li>
</ul>
<h3 id="File-System-Namespace"><a href="#File-System-Namespace" class="headerlink" title="File System Namespace"></a>File System Namespace</h3><ul>
<li>File System Namespace的結構與傳統檔案系統相同，並且支持對檔案的創建、刪除、搬移，重新命名等操作。</li>
<li>支持用戶容量配額與訪問權限控制。</li>
<li>不支持硬連結與軟連結。</li>
<li>NameNode負責管理File System Namespace。</li>
<li>任何File System Namespace與其屬性的改變，都記錄在NameNode中。</li>
<li>應用程序可以設置文件的副本係數，副本係數的資訊儲存在NameNode中。</li>
</ul>
<h3 id="Data-Replication"><a href="#Data-Replication" class="headerlink" title="Data Replication"></a>Data Replication</h3><ul>
<li>HDFS設計目的是為了在跨機器的集群中，提供高可靠的超大文件儲存服務。</li>
<li>為了高容錯能力，將Blocks進行多副本方式儲存。</li>
<li>每個文件的Block大小與副本係數都是可以設置的。</li>
<li>副本係數是指一個Block副本的數量。</li>
<li>預設副本係數為3。生產環境設為5或7。</li>
<li>副本係數可以在文件創建設置，也可以在之後進行修改。</li>
<li>HDFS文件都是一次性寫入的(write-once)，並嚴格要求一次只能有一個Client進行寫入。</li>
<li>NameNode管理Block的複製，並週期性的接收DataNode的Heartbeat與BlockReport，</li>
<li>根據BlockReport，對寫入文件的副本進行合理的安排。</li>
</ul>
<h3 id="Replica-Selection"><a href="#Replica-Selection" class="headerlink" title="Replica Selection"></a>Replica Selection</h3><ul>
<li>優先將一個Block的副本放置在不同的機器上。</li>
<li>分為積架環境與一般環境說明:<ul>
<li>一般環境:<ul>
<li>在DataNode中執行文件寫入:<ul>
<li>挑選當前DataNode進行第一個Block副本放置處，節省網路傳輸成本。</li>
<li>其他副本則以不重複原則，進行隨機挑選。</li>
</ul>
</li>
<li>在其他節點執行文件寫入:<ul>
<li>以不重複原則，進行隨機挑選。</li>
</ul>
</li>
</ul>
</li>
<li>積架環境:<ul>
<li>在DataNode中執行文件寫入:<ul>
<li>挑選當前DataNode進行第一個Block副本放置處。節省網路傳輸成本。</li>
<li>優先挑選不同的積架中的DataNode進行寫入，直到所有副本處理完畢。</li>
</ul>
</li>
<li>在其他節點執行文件寫入:<ul>
<li>根據資源狀況挑選DataNode。</li>
<li>優先挑選不同的積架中的DataNode進行寫入，直到所有副本處理完畢。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/23/hadoop-compile/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="2318">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="2318">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/23/hadoop-compile/" itemprop="url">Compile Hadoop source code</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-23T12:33:33+08:00">
                2017-08-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Compile-Hadoop-source-code"><a href="#Compile-Hadoop-source-code" class="headerlink" title="Compile Hadoop source code"></a>Compile Hadoop source code</h2><h3 id="編譯步驟"><a href="#編譯步驟" class="headerlink" title="編譯步驟"></a>編譯步驟</h3><h4 id="基本訊息"><a href="#基本訊息" class="headerlink" title="基本訊息"></a>基本訊息</h4><ul>
<li>OS: CentOS 6.5 64bit</li>
<li>Hadoop: 2.8.1</li>
<li>JDK: 8u144</li>
<li>Maven: 3.3.9</li>
<li>ProtocolBuffer: 2.5.0</li>
<li>Findbugs: 1.3.9</li>
</ul>
<p>####設置Hadoop目錄</p>
<ul>
<li>Hadoop source code:<ul>
<li><a href="http://hadoop.apache.org/releases.html" title="Hadoop releases" target="_blank" rel="external">Hadoop官網下載</a><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /opt/sourcecode/</span></div><div class="line">[root@hadoop-01 sourcecode]<span class="comment"># ls</span></div><div class="line">hadoop-2.8.1-src.tar.gz  <span class="comment">## 已下載的hadoop 2.8.1 source code壓縮包</span></div><div class="line">[root@hadoop-01 sourcecode]<span class="comment"># tar -xzvf hadoop-2.8.1-src.tar.gz</span></div><div class="line">[root@hadoop-01 sourcecode]<span class="comment"># ls</span></div><div class="line">hadoop-2.8.1-src</div><div class="line">hadoop-2.8.1-src.tar.gz</div><div class="line">[root@hadoop-01 sourcecode]<span class="comment"># cd hadoop-2.8.1-src</span></div><div class="line">[root@hadoop-01 hadoop-2.8.1-src]<span class="comment"># ll</span></div><div class="line">total 228</div><div class="line">-rw-rw-r--.  1 root root 15623 May 24 07:14 BUILDING.txt</div><div class="line">drwxr-xr-x.  4 root root  4096 Aug 21 00:38 dev-support</div><div class="line">drwxr-xr-x.  4 root root  4096 Aug 21 02:01 hadoop-assemblies</div><div class="line">drwxr-xr-x.  4 root root  4096 Aug 21 02:01 hadoop-build-tools</div><div class="line">drwxrwxr-x.  3 root root  4096 Aug 21 02:13 hadoop-client</div><div class="line">drwxr-xr-x. 11 root root  4096 Aug 21 02:04 hadoop-common-project</div><div class="line">drwxr-xr-x.  3 root root  4096 Aug 21 02:13 hadoop-dist</div><div class="line">drwxr-xr-x.  9 root root  4096 Aug 21 02:07 hadoop-hdfs-project</div><div class="line">drwxr-xr-x. 10 root root  4096 Aug 21 02:11 hadoop-mapreduce-project</div><div class="line">drwxr-xr-x.  4 root root  4096 Aug 21 02:01 hadoop-maven-plugins</div><div class="line">drwxr-xr-x.  3 root root  4096 Aug 21 02:13 hadoop-minicluster</div><div class="line">drwxr-xr-x.  4 root root  4096 Aug 21 02:01 hadoop-project</div><div class="line">drwxr-xr-x.  3 root root  4096 Aug 21 02:01 hadoop-project-dist</div><div class="line">drwxr-xr-x. 19 root root  4096 Aug 21 02:13 hadoop-tools</div><div class="line">drwxr-xr-x.  4 root root  4096 Aug 21 02:09 hadoop-yarn-project</div><div class="line">-rw-rw-r--.  1 root root 99253 May 24 07:14 LICENSE.txt</div><div class="line">-rw-------.  1 root root   289 Aug 21 00:45 nohup.out</div><div class="line">-rw-rw-r--.  1 root root 15915 May 24 07:14 NOTICE.txt</div><div class="line">drwxrwxr-x.  2 root root  4096 Jun  2 14:24 patchprocess</div><div class="line">-rw-rw-r--.  1 root root 20477 May 29 06:36 pom.xml</div><div class="line">-rw-r--r--.  1 root root  1366 May 20 13:30 README.txt</div><div class="line">-rwxrwxr-x.  1 root root  1841 May 24 07:14 start-build-env.sh</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>BUILDING.txt文件中列出編譯的基本需求，以及編譯時需要注意的地方，可以在編譯的過程中對照著看。</p>
<h4 id="Java的安裝與配置"><a href="#Java的安裝與配置" class="headerlink" title="Java的安裝與配置"></a>Java的安裝與配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># ls cd /opt/software/</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">jdk-8u144-linux-x64.tar  <span class="comment">## 已下載的JDK壓縮包</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># mkdir -p /usr/java</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># mv jdk-8u144-linux-x64.tar /usr/java</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># cd /usr/java</span></div><div class="line">[root@hadoop-01 java]<span class="comment"># tar -vxf jdk-8u144-linux-x64.tar</span></div><div class="line">[root@hadoop-01 java]<span class="comment"># ll</span></div><div class="line">drwxr-xr-x. 8 uucp  143      4096 Jul 22 13:11 jdk1.8.0_144</div><div class="line">-rw-r--r--. 1 root root 377835520 Aug 20 22:13 jdk-8u144-linux-x64.tar</div><div class="line">[root@hadoop-01 java]<span class="comment"># chown -R root:root jdk1.8.0_144</span></div><div class="line">[root@hadoop-01 java]<span class="comment"># ll</span></div><div class="line">drwxr-xr-x. 8 root root      4096 Jul 22 13:11 jdk1.8.0_144</div><div class="line">-rw-r--r--. 1 root root 377835520 Aug 20 22:13 jdk-8u144-linux-x64.tar</div><div class="line">[root@hadoop-01 java]<span class="comment"># vim /etc/profile</span></div><div class="line"><span class="comment">## 新增下列兩行在文件中的任一位置，設置Java環境變量</span></div><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_144</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></div><div class="line">[root@hadoop-01 java]<span class="comment"># source /etc/profile</span></div><div class="line">[root@hadoop-01 java]<span class="comment"># which java  ## 確認Java環境變量設置成功</span></div><div class="line">/usr/java/jdk1.8.0_144/bin/java</div><div class="line">[root@hadoop-01 java]<span class="comment"># java -version</span></div><div class="line">java version <span class="string">"1.8.0_144"</span></div><div class="line">Java(TM) SE Runtime Environment (build 1.8.0_144-b01)</div><div class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)</div></pre></td></tr></table></figure>
<h4 id="Maven的安裝與配置"><a href="#Maven的安裝與配置" class="headerlink" title="Maven的安裝與配置"></a>Maven的安裝與配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /opt/software/</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">apache-maven-3.3.9-bin.tar.gz  <span class="comment">## 已下載的Maven壓縮包</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># tar -zxvf apache-maven-3.3.9-bin.tar.gz</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">apache-maven-3.3.9 </div><div class="line">apache-maven-3.3.9-bin.tar.gz</div><div class="line">[root@hadoop-01 software]<span class="comment"># vim /etc/profile</span></div><div class="line"><span class="comment">## 新增下列兩行在文件中的任一位置，設置Maven環境變量</span></div><div class="line"><span class="built_in">export</span> MAVEN_HOME=/opt/software/apache-maven-3.3.9</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$MAVEN_HOME</span>/bin:<span class="variable">$PATH</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># source /etc/profile</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># mvn -version  ## 確認Maven環境變量設置成功</span></div><div class="line">Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)</div><div class="line">Maven home: /opt/software/apache-maven-3.3.9</div><div class="line">Java version: 1.8.0_144, vendor: Oracle Corporation</div><div class="line">Java home: /usr/java/jdk1.8.0_144/jre</div><div class="line">Default locale: en_US, platform encoding: UTF-8</div><div class="line">OS name: <span class="string">"linux"</span>, version: <span class="string">"2.6.32-431.el6.x86_64"</span>, arch: <span class="string">"amd64"</span>, family: <span class="string">"unix"</span></div></pre></td></tr></table></figure>
<h4 id="Autoconf的安裝"><a href="#Autoconf的安裝" class="headerlink" title="Autoconf的安裝"></a>Autoconf的安裝</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /opt/software/</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># wget http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gz</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">autoconf-2.69.tar.gz</div><div class="line">[root@hadoop-01 software]<span class="comment"># tar -zxvf autoconf-2.69.tar.gz</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">autoconf-2.69</div><div class="line">autoconf-2.69.tar.gz</div><div class="line">[root@hadoop-01 software]<span class="comment"># cd autoconf-2.69 </span></div><div class="line">[root@hadoop-01 autoconf-2.69]<span class="comment"># ./configure</span></div><div class="line">[root@hadoop-01 autoconf-2.69]<span class="comment"># make &amp; make install</span></div><div class="line">[root@hadoop-01 autoconf-2.69]<span class="comment"># autoconf --version  ## 確認Autoconf安裝成功</span></div><div class="line">autoconf (GNU Autoconf) 2.69</div></pre></td></tr></table></figure>
<h4 id="Automake的安裝"><a href="#Automake的安裝" class="headerlink" title="Automake的安裝"></a>Automake的安裝</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /opt/software/</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># wget http://ftp.gnu.org/gnu/automake/automake-1.14.tar.gz</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">automake-1.14.tar.gz</div><div class="line">[root@hadoop-01 software]<span class="comment"># tar -xvzf automake-1.14.tar.gz</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">automake-1.14</div><div class="line">automake-1.14.tar.gz</div><div class="line">[root@hadoop-01 software]<span class="comment"># cd automake-1.14</span></div><div class="line">[root@hadoop-01 automake-1.14]<span class="comment"># ./configure</span></div><div class="line">[root@hadoop-01 automake-1.14]<span class="comment"># make &amp; make install</span></div><div class="line">[root@hadoop-01 automake-1.14]<span class="comment"># automake --version  ## 確認Automake安裝成功</span></div><div class="line">automake (GNU automake) 1.14</div></pre></td></tr></table></figure>
<h4 id="Protobuf安装"><a href="#Protobuf安装" class="headerlink" title="Protobuf安装"></a>Protobuf安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /opt/software/</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">protobuf-2.5.0.tar.gz  <span class="comment">## 已下載的Protobuf壓縮包</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># tar -zxvf protobuf-2.5.0.tar.gz</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls </span></div><div class="line">protobuf-2.5.0 </div><div class="line">protobuf-2.5.0.tar.gz</div><div class="line">[root@hadoop-01 software]<span class="comment"># cd protobuf-2.5.0</span></div><div class="line">[root@hadoop-01 protobuf-2.5.0]<span class="comment"># ls</span></div><div class="line">[root@hadoop-01 protobuf-2.5.0]<span class="comment"># yum install -y gcc gcc-c++ make cmake</span></div><div class="line">[root@hadoop-01 protobuf-2.5.0]<span class="comment"># ./configure --prefix=/usr/local/protobuf</span></div><div class="line">[root@hadoop-01 protobuf-2.5.0]<span class="comment"># make &amp;&amp; make install</span></div><div class="line">[root@hadoop-01 protobuf-2.5.0]<span class="comment"># vim /etc/profile</span></div><div class="line"><span class="comment">## 新增下列兩行在文件中的任一位置，設置Protobuf環境變量</span></div><div class="line"><span class="built_in">export</span> PROTOC_HOME=/usr/<span class="built_in">local</span>/protobuf</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PROTOC_HOME</span>/bin:<span class="variable">$PATH</span></div><div class="line">[root@hadoop-01 protobuf-2.5.0]<span class="comment"># source /etc/profile</span></div><div class="line">[root@hadoop-01 protobuf-2.5.0]<span class="comment"># protoc --version   ## 確認Protobuf環境變量設置成功</span></div><div class="line">libprotoc 2.5.0</div></pre></td></tr></table></figure>
<h4 id="Findbugs安装"><a href="#Findbugs安装" class="headerlink" title="Findbugs安装"></a>Findbugs安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /opt/software</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">findbugs-1.3.9.zip  <span class="comment">## 已下載的Findbugs壓縮包</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># unzip findbugs-1.3.9.zip</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># ls</span></div><div class="line">findbugs-1.3.9</div><div class="line">findbugs-1.3.9.zip</div><div class="line">[root@hadoop-01 software]<span class="comment"># vi /etc/profile</span></div><div class="line"><span class="comment">## 新增下列兩行在文件中的任一位置，設置Findbugs環境變量</span></div><div class="line"><span class="built_in">export</span> FINDBUGS_HOME=/opt/software/findbugs-1.3.9</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$FINDBUGS_HOME</span>/bin:<span class="variable">$PATH</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># source /etc/profile</span></div><div class="line">[root@hadoop-01 software]<span class="comment"># findbugs -version   ## 確認Findbugs環境變量設置成功</span></div><div class="line">1.3.9</div></pre></td></tr></table></figure>
<h4 id="安装其他依賴"><a href="#安装其他依賴" class="headerlink" title="安装其他依賴"></a>安装其他依賴</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># yum install -y openssl openssl-devel svn ncurses-devel zlib-devel libtool</span></div><div class="line">[root@hadoop-01 ~]<span class="comment"># yum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop</span></div></pre></td></tr></table></figure>
<h4 id="進行編譯"><a href="#進行編譯" class="headerlink" title="進行編譯"></a>進行編譯</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@hadoop-01 ~]<span class="comment"># cd /opt/sourcecode/hadoop-2.8.1-src</span></div><div class="line">[root@hadoop-01 hadoop-2.8.1-src]<span class="comment"># mvn clean package -Pdist,native -DskipTests -Dtar</span></div><div class="line"><span class="comment">## 編譯過程中，需保證網路暢通，因為maven會自動下載依賴的jar檔</span></div><div class="line"><span class="comment">## 若在下載的過程中有某個jar卡住，可以使用Ctrl+C退出後，重新輸入編譯命令</span></div><div class="line"><span class="comment">## 編譯完成的Hadoop jar放置在 /opt/sourcecode/hadoop-2.8.1-src/hadoop-dist/target/hadoop-2.8.1.tar.gz</span></div></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">2318</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">Tags</span>
                
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">2318</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  
  

  

  

  

</body>
</html>
